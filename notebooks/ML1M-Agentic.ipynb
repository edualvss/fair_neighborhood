{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Multi-Agentic Recommendation System Pipeline\n",
        "This notebook demonstrates a modular, multi-agentic pipeline for evaluating recommender systems with context engineering.\n",
        "\n",
        "Each agent is responsible for a specific function, and context engineering is used to enhance the recommendation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61a5da1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Go to root dir to load the code from `src` and dataset from the specific folder\n",
        "import os\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eas/Documents/GitHub/fair_neighborhood/venv/lib/python3.11/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from scipy.sparse import lil_matrix\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
        "from recpack.preprocessing.filters import Deduplicate, MinRating, MinItemsPerUser\n",
        "from recpack.scenarios import WeakGeneralization, StrongGeneralization\n",
        "\n",
        "from hyperopt import fmin, tpe, hp\n",
        "\n",
        "# helpers & metrics\n",
        "from src.helper_functions.data_formatting import *\n",
        "from src.helper_functions.metrics_accuracy import *\n",
        "from src.helper_functions.metrics_coverage import *\n",
        "from src.helper_functions.metrics_exposure import *\n",
        "\n",
        "# models\n",
        "from src.recommenders.ease import myEASE\n",
        "from src.recommenders.slim_bn import BNSLIM\n",
        "from src.recommenders.fslr import FSLR\n",
        "from src.recommenders.slim_bn_admm import BNSLIM_ADMM\n",
        "from src.recommenders.mf_fair import FairMF\n",
        "from src.recommenders.fda import FDA_bpr\n",
        "\n",
        "import json\n",
        "import re\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "# import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b9a6e713",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(filename=\"recsys.log\", level=logging.WARN, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2365d484",
      "metadata": {},
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31bd30ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/p_/s2y5jw396vjd9c8fql74n7600000gn/T/ipykernel_8945/2820513550.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  users[\"Gender\"] = users[\"Gender\"].replace({\"M\": 0, \"F\": 1})\n"
          ]
        }
      ],
      "source": [
        "# load ratings.dat from ml-1m folder\n",
        "ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, usecols=[0,1,2,3], names=[\"User_id\",\"Item_id\",\"Rating\",\"Timestamp\"], engine=\"python\")\n",
        "\n",
        "# load movies.dat from ml-1m folder\n",
        "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, usecols=[0,1,2], names=[\"Item_id\", \"Title\", \"Genre\"], encoding=\"latin-1\", engine=\"python\")\n",
        "movies[\"Genre\"] = movies[\"Genre\"].apply(lambda x: x.split(\"|\"))\n",
        "movies_items = movies\n",
        "movies = movies.explode(\"Genre\")\n",
        "\n",
        "# load users.dat from ml-1m folder\n",
        "users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", header=None, usecols=[0,1], names=[\"User_id\", \"Gender\"], encoding=\"latin-1\", engine=\"python\")\n",
        "\n",
        "# replace \"M\" with 0 and \"F\" with 1 in the \"Gender\" column\n",
        "users[\"Gender\"] = users[\"Gender\"].replace({\"M\": 0, \"F\": 1})\n",
        "\n",
        "# join ratings on users with User_id\n",
        "ratings = pd.merge(ratings, users, on=\"User_id\", how=\"left\")\n",
        "ratings['datetime'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
        "ratings = ratings.sort_values('datetime').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e812a5",
      "metadata": {},
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f2cd257",
      "metadata": {},
      "source": [
        "#### Temporal Splitting\n",
        "\n",
        "Split the dataset into train and test sets based on a timestamp for temporal evaluation.\n",
        "\n",
        "* 50% oldest interactions for train (base set)\n",
        "* 50% newest interactions for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "24071c3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 500105\n",
            "Test set size: 500104\n",
            "Split timestamp: 973018006.0\n",
            "Split datetime: 2000-10-31 18:46:46\n"
          ]
        }
      ],
      "source": [
        "# Split ratings into train and test sets based on timestamp (temporal split)\n",
        "# Example: Use the 80th percentile of timestamps as the split point\n",
        "#split_point = ratings[\"Timestamp\"].quantile(0.8)\n",
        "split_point = ratings[\"Timestamp\"].quantile(0.5) # 50% temporal split\n",
        "train_ratings = ratings[ratings[\"Timestamp\"] <= split_point]\n",
        "test_ratings = ratings[ratings[\"Timestamp\"] > split_point]\n",
        "\n",
        "print(f\"Train set size: {len(train_ratings)}\")\n",
        "print(f\"Test set size: {len(test_ratings)}\")\n",
        "print(f\"Split timestamp: {split_point}\")\n",
        "print(f\"Split datetime: {pd.to_datetime(split_point, unit='s')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "46a1e152",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train - Users: 3255 | Items: 3551 \n",
            "Test - Users: 3415 | Items: 3643 \n"
          ]
        }
      ],
      "source": [
        "print(\"Train - Users: {} | Items: {} \".format(train_ratings.User_id.unique().shape[0],train_ratings.Item_id.unique().shape[0]))\n",
        "print(\"Test - Users: {} | Items: {} \".format(test_ratings.User_id.unique().shape[0],test_ratings.Item_id.unique().shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7dfff6a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea322ea82a48434e8793558ff86fd2bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/290311 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8404b223746d480fbbd1cd67ccd86d72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/290311 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ratings_pp = DataFramePreprocessor(\"Item_id\", \"User_id\",\"Timestamp\")\n",
        "\n",
        "# define filters\n",
        "deduplicate = Deduplicate(\"Item_id\", \"User_id\", \"Timestamp\")\n",
        "min_rating_filter = MinRating(4, \"Rating\")\n",
        "min_items_per_user_filter = MinItemsPerUser(10, \"Item_id\", \"User_id\") # Don't filter users with less than 10 interactions --- IGNORE ---\n",
        "\n",
        "# add filters to pre-processor\n",
        "ratings_pp.add_filter(deduplicate)\n",
        "ratings_pp.add_filter(min_rating_filter)\n",
        "ratings_pp.add_filter(min_items_per_user_filter)\n",
        "\n",
        "# create interaction matrix object\n",
        "# im = ratings_pp.process(ratings)\n",
        "im_train = ratings_pp.process(train_ratings)\n",
        "# im_test = ratings_pp.process(test_ratings)\n",
        "#im, im_train, im_test = ratings_pp.process_many(ratings, train_ratings, test_ratings)\n",
        "\n",
        "# apply filters to ratings frame directly\n",
        "#ratings = min_items_per_user_filter.apply(min_rating_filter.apply(deduplicate.apply(ratings)))\n",
        "#train_ratings = min_items_per_user_filter.apply(min_rating_filter.apply(deduplicate.apply(train_ratings)))\n",
        "ratings = min_rating_filter.apply(deduplicate.apply(ratings))\n",
        "train_ratings = min_rating_filter.apply(deduplicate.apply(train_ratings))\n",
        "\n",
        "movies = movies[movies[\"Item_id\"].isin(ratings[\"Item_id\"].unique())] # only keep items that are in the filtered ratings\n",
        "raw_genre_dict = dict(movies.groupby(\"Genre\")[\"Item_id\"].apply(lambda x: list(set(x))))\n",
        "\n",
        "# genre - inner iids dictionary\n",
        "inner_genre_dict = {\n",
        "    genre: get_inner_item_ids(ratings_pp, raw_iids) for genre, raw_iids in raw_genre_dict.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5064073e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### UPDATE\n",
        "# Remove year from movie titles for better readability\n",
        "YEAR_MOVIE_TITLES_PATTERN = r'\\s*\\(\\d{4}\\)'\n",
        "original_movie_titles = movies.Title.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "75965873",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### UPDATE\n",
        "# Create a mapping from original titles to updated titles without year\n",
        "original_to_updated_titles = {title : re.sub(YEAR_MOVIE_TITLES_PATTERN,'',title) for title in original_movie_titles}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "742d95fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### UPDATE\n",
        "# Fix titles that have \", The\" or \", A\" at the end\n",
        "for title in original_to_updated_titles:\n",
        "    if \",\" in original_to_updated_titles[title]:\n",
        "        parts = original_to_updated_titles[title].split(\",\")\n",
        "        if len(parts) == 2:\n",
        "            if parts[1] == ' The':\n",
        "                original_to_updated_titles[title] = 'The ' + parts[0]\n",
        "            elif parts[1] == ' A':\n",
        "                original_to_updated_titles[title] = 'A ' + parts[0]\n",
        "        \n",
        "updated_to_original_titles = {original_to_updated_titles[original_title] : original_title for original_title in original_to_updated_titles}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "917b1a4e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>3349</th>\n",
              "      <th>3350</th>\n",
              "      <th>3351</th>\n",
              "      <th>3352</th>\n",
              "      <th>3353</th>\n",
              "      <th>3354</th>\n",
              "      <th>3355</th>\n",
              "      <th>3356</th>\n",
              "      <th>3357</th>\n",
              "      <th>3358</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3359 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...  3349  \\\n",
              "0     1     1     1     1     1     1     1     1     1     1  ...     0   \n",
              "1     1     0     0     0     1     0     0     0     0     1  ...     0   \n",
              "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "3     1     0     1     0     0     0     0     0     1     1  ...     0   \n",
              "4     0     1     1     1     1     0     1     0     1     0  ...     0   \n",
              "\n",
              "   3350  3351  3352  3353  3354  3355  3356  3357  3358  \n",
              "0     0     0     0     0     0     0     0     0     0  \n",
              "1     0     0     0     0     0     0     0     0     0  \n",
              "2     0     0     0     0     0     0     0     0     0  \n",
              "3     0     0     0     0     0     0     0     0     0  \n",
              "4     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[5 rows x 3359 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### UPDATE\n",
        "pd.DataFrame.sparse.from_spmatrix(im_train.binary_values).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7c465c4c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([6037]), array([3]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_raw_user_ids(ratings_pp,[3]), get_inner_user_ids(ratings_pp,[6037])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f45cb31f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base data - U[3153] | I[3359]\n"
          ]
        }
      ],
      "source": [
        "#print(f\"Full data - U[{len(im.active_users)}] | I[{len(im.active_items)}]\")\n",
        "print(f\"Base data - U[{len(im_train.active_users)}] | I[{len(im_train.active_items)}]\")\n",
        "#print(f\"Test data - U[{len(im_test.active_users)}] | I[{len(im_test.active_items)}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af974c2",
      "metadata": {},
      "source": [
        "## Data Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e4f278",
      "metadata": {},
      "source": [
        "### Full dataset"
      ]
    },
    {
      "cell_type": "raw",
      "id": "7a327ad7",
      "metadata": {},
      "source": [
        "# compute sparsity after filtering\n",
        "sparsity = 1 - im.density\n",
        "\n",
        "# calculate user interaction and item popularity ranges\n",
        "user_interactions = im.binary_values.sum(axis=1)\n",
        "item_popularities = im.binary_values.sum(axis=0)\n",
        "print(f\"User interaction ranges from {user_interactions.min()} to {user_interactions.max()}. Item popularity ranges from {item_popularities.min()} to {item_popularities.max()}.\")\n",
        "\n",
        "# get the raw ids of all users involved\n",
        "raw_uids = get_raw_user_ids(ratings_pp, im.active_users)\n",
        "\n",
        "# create uid - gender mapping df\n",
        "gender_mapping_df = ratings[ratings[\"User_id\"].isin(raw_uids)][[\"User_id\", \"Gender\"]].drop_duplicates()\n",
        "\n",
        "# get the raw/inner ids of all females involved\n",
        "raw_uids_f = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 1, \"User_id\"].to_numpy()\n",
        "inner_uids_f = get_inner_user_ids(ratings_pp, raw_uids_f)\n",
        "\n",
        "# get the raw/inner ids of all males involved\n",
        "raw_uids_m = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 0, \"User_id\"].to_numpy()\n",
        "inner_uids_m = get_inner_user_ids(ratings_pp, raw_uids_m)\n",
        "\n",
        "num_interactions_f, num_interactions_m = im.binary_values[inner_uids_f].sum(), im.binary_values[inner_uids_m].sum()\n",
        "\n",
        "# table stats\n",
        "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
        "statTable1.add_row([\"ML1M\", str(im.num_active_users), str(im.num_active_items), str(im.num_interactions), str(round(sparsity*100,2))])\n",
        "print(statTable1)\n",
        "\n",
        "statTable2 = PrettyTable([\"data set\",\"attribute\",\"|F|\",\"int(F)\",\"|M|\",\"int(M)\"])\n",
        "statTable2.add_row([\"ML1M\", \"gender\", str(len(raw_uids_f)), str(num_interactions_f), str(len(raw_uids_m)), str(num_interactions_m)])\n",
        "print(statTable2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e408d0c8",
      "metadata": {},
      "source": [
        "### Base dataset (50% oldest interactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c7286e47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User interaction ranges from 10 to 1063. Item popularity ranges from 1 to 1413.\n",
            "+----------+------+------+--------+----------+\n",
            "| data set | |U|  | |I|  | int(I) | sparsity |\n",
            "+----------+------+------+--------+----------+\n",
            "|   ML1M   | 3153 | 3359 | 290311 |  97.26   |\n",
            "+----------+------+------+--------+----------+\n",
            "+----------+-----------+-----+--------+------+--------+\n",
            "| data set | attribute | |F| | int(F) | |M|  | int(M) |\n",
            "+----------+-----------+-----+--------+------+--------+\n",
            "|   ML1M   |   gender  | 907 | 75923  | 2246 | 214388 |\n",
            "+----------+-----------+-----+--------+------+--------+\n"
          ]
        }
      ],
      "source": [
        "# compute sparsity after filtering\n",
        "sparsity = 1 - im_train.density\n",
        "\n",
        "# calculate user interaction and item popularity ranges\n",
        "user_interactions = im_train.binary_values.sum(axis=1)\n",
        "item_popularities = im_train.binary_values.sum(axis=0)\n",
        "print(f\"User interaction ranges from {user_interactions.min()} to {user_interactions.max()}. Item popularity ranges from {item_popularities.min()} to {item_popularities.max()}.\")\n",
        "\n",
        "# get the raw ids of all users involved\n",
        "raw_uids = get_raw_user_ids(ratings_pp, im_train.active_users)\n",
        "\n",
        "# create uid - gender mapping df\n",
        "gender_mapping_df = train_ratings[train_ratings[\"User_id\"].isin(raw_uids)][[\"User_id\", \"Gender\"]].drop_duplicates()\n",
        "\n",
        "# get the raw/inner ids of all females involved\n",
        "raw_uids_f = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 1, \"User_id\"].to_numpy()\n",
        "inner_uids_f = get_inner_user_ids(ratings_pp, raw_uids_f)\n",
        "\n",
        "# get the raw/inner ids of all males involved\n",
        "raw_uids_m = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 0, \"User_id\"].to_numpy()\n",
        "inner_uids_m = get_inner_user_ids(ratings_pp, raw_uids_m)\n",
        "\n",
        "num_interactions_f, num_interactions_m = im_train.binary_values[inner_uids_f].sum(), im_train.binary_values[inner_uids_m].sum()\n",
        "\n",
        "# table stats\n",
        "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
        "statTable1.add_row([\"ML1M\", str(im_train.num_active_users), str(im_train.num_active_items), str(im_train.num_interactions), str(round(sparsity*100,2))])\n",
        "print(statTable1)\n",
        "\n",
        "statTable2 = PrettyTable([\"data set\",\"attribute\",\"|F|\",\"int(F)\",\"|M|\",\"int(M)\"])\n",
        "statTable2.add_row([\"ML1M\", \"gender\", str(len(raw_uids_f)), str(num_interactions_f), str(len(raw_uids_m)), str(num_interactions_m)])\n",
        "print(statTable2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cf0b9171",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2246, 907)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inner_uids_m.shape[0], inner_uids_f.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75dfbf06",
      "metadata": {},
      "source": [
        "### Train and test backbones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9ecf070d",
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 1994"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a3538b16",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88423b0f551a4d7aa99b5dad34603393",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c772ae1ea94f44b99968720a93ee7153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model ease...\n",
            "2025-12-17 23:09:10,542 - base - recpack - INFO - Fitting myEASE complete - Took 1.33s\n",
            "Fit time: {'ease': 1.3444628715515137}\n",
            "Model: ease | NDCG@10: 0.3066 (±0.2309) | Recall@10: 0.2915 (±0.2135)\n",
            "Model: ease | NDCG@20: 0.3051 (±0.1935) | Recall@20: 0.3192 (±0.1952)\n"
          ]
        }
      ],
      "source": [
        "class TrainedBackbones:\n",
        "    \n",
        "    def __init__(self,interaction_matrix):\n",
        "        self.im = interaction_matrix\n",
        "        \n",
        "        # Create scenario for train and test the backbone        \n",
        "        self.scenario = WeakGeneralization(validation=True, seed=SEED)\n",
        "        self.scenario.split(self.im)\n",
        "\n",
        "        # Load optimized parameters\n",
        "        with open(f\"ml-1m/{SEED}/opt_params.json\", \"r\") as f: opt_params = json.load(f)\n",
        "        # Initialize models\n",
        "        self.models = self.initialize_models(opt_params)\n",
        "        # Prepare to output\n",
        "        self.predictions = dict()\n",
        "        self.fit_time = dict()\n",
        "        self.iters_num = dict()\n",
        "\n",
        "        # Build the backbone models and generate the outputs\n",
        "        self.train_test_models()\n",
        "        \n",
        "    def initialize_models(self,opt_params):\n",
        "        return {\n",
        "            \"ease\": myEASE(l2=opt_params[\"ease\"][\"l2\"], method=\"user\"),\n",
        "        #   \"bnslim\": BNSLIM(knn=100, l1=opt_params[\"bnslim\"][\"l1\"], l2=opt_params[\"bnslim\"][\"l2\"], l3=opt_params[\"bnslim\"][\"l3\"], maxIter=50, method=\"user\", seed=SEED),\n",
        "        #    \"fslr\": FSLR(l1=opt_params[\"fslr\"][\"l1\"], l2=opt_params[\"fslr\"][\"l2\"], method=\"user\"),\n",
        "        #    \"bnslim_admm\": BNSLIM_ADMM(l1=opt_params[\"bnslim_admm\"][\"l1\"], l2=opt_params[\"bnslim_admm\"][\"l2\"], l3=opt_params[\"bnslim_admm\"][\"l3\"], method=\"user\"),\n",
        "        #    \"fairmf\": FairMF(batch_size=im.num_active_users, l2=opt_params[\"fairmf\"][\"l2\"], learning_rate=opt_params[\"fairmf\"][\"learning_rate\"], num_factors=opt_params[\"fairmf\"][\"num_factors\"], seed=SEED),\n",
        "        #    \"fda\": FDA_bpr(noise_ratio=opt_params[\"fda\"][\"noise_ratio\"], num_ng=opt_params[\"fda\"][\"num_ng\"],seed=SEED)\n",
        "        }\n",
        "\n",
        "    def train_test_models(self):\n",
        "\n",
        "        #### PARAMETERS INIT\n",
        "        # parameters for fairmf\n",
        "        sst_field = torch.zeros((self.im.num_active_users, self.im.num_active_items), dtype=torch.bool)\n",
        "        sst_field[inner_uids_f, :] = True\n",
        "        # parameters for fda\n",
        "        users_features = np.zeros(self.im.num_active_users); users_features[inner_uids_m] = 1\n",
        "\n",
        "        for model_name, model in self.models.items():\n",
        "            print(f\"Training model {model_name}...\")\n",
        "\n",
        "            params = {}\n",
        "            if model_name == \"fslr\":\n",
        "                params = {\"inner_ids_pr\": inner_uids_f, \"inner_ids_npr\": inner_uids_m}\n",
        "            elif model_name in [\"bnslim\", \"bnslim_admm\"]:\n",
        "                params = {\"inner_ids_npr\": inner_uids_m}\n",
        "            elif model_name == \"fairmf\":\n",
        "                params = {\"sst_field\": sst_field}\n",
        "            elif model_name == \"fda\":\n",
        "                params = {\"users_features\": users_features}\n",
        "            \n",
        "            start_time = time.time()\n",
        "            model.fit(self.scenario.full_training_data.binary_values, **params)\n",
        "            self.fit_time[model_name] = time.time() - start_time\n",
        "            print(f\"Fit time: {self.fit_time}\")\n",
        "\n",
        "            if model_name == \"fairmf\":\n",
        "                self.iters_num[model_name] = model.epochs\n",
        "            else:\n",
        "                self.iters_num[model_name] = model.iters\n",
        "\n",
        "            # generate predictions and mask training interactions\n",
        "            y_pred = None\n",
        "            if model_name == \"fda\":\n",
        "                y_pred = model.model_.predict()\n",
        "            else:\n",
        "                y_pred = model.predict(self.scenario.full_training_data.binary_values)\n",
        "            self.predictions[model_name] = y_pred.toarray()\n",
        "            # mask\n",
        "            self.predictions[model_name][self.scenario.full_training_data.binary_values.nonzero()] = -np.inf\n",
        "\n",
        "            for K in [10,20]:\n",
        "                ndcg, std_ndcg = tndcg_at_n(self.predictions[model_name], self.scenario.test_data_out.binary_values, K)\n",
        "                recall, std_recall = recall_at_n(self.predictions[model_name], self.scenario.test_data_out.binary_values, K)\n",
        "\n",
        "                print(f\"Model: {model_name} | NDCG@{K}: {ndcg:.4f} (±{std_ndcg:.4f}) | Recall@{K}: {recall:.4f} (±{std_recall:.4f})\"  )\n",
        "\n",
        "\n",
        "    def get_items_ranking(self, items_ids):\n",
        "        raw_items_ids = get_raw_item_ids(ratings_pp,items_ids)      # RAW: from dataset\n",
        "        #inner_items_ids = get_inner_item_ids(ratings_pp,items_ids) # INNER: used by recpack\n",
        "        rec_items = []\n",
        "        for i, item_id in enumerate(raw_items_ids):\n",
        "            item_original_title = movies_items[movies_items.Item_id == item_id].Title.values[0]\n",
        "            rec_item = {\n",
        "                \"item_id\": int(item_id),\n",
        "                \"item_title\": original_to_updated_titles[item_original_title],\n",
        "                \"position\": i+1\n",
        "            }\n",
        "            rec_items.append(rec_item)\n",
        "\n",
        "        return rec_items\n",
        "\n",
        "    def get_candidate_items(self, user_id, model_name, top_k):\n",
        "        user_top_items = get_topn_indices(self.predictions[model_name],top_k)[user_id]\n",
        "        return self.get_items_ranking(user_top_items)\n",
        "\n",
        "    def get_models_name(self):\n",
        "        return self.models.keys()\n",
        "\n",
        "    def get_raw_item_ids_from_titles_in_catalog(self, item_titles : list[str]):\n",
        "        catalog = movies.drop_duplicates(subset=['Item_id','Title'])\n",
        "        return catalog[catalog.Title.isin(item_titles)]['Item_id'].tolist()\n",
        "\n",
        "\n",
        "#backbones = TrainedBackbones(im)\n",
        "backbones = TrainedBackbones(im_train)\n",
        "\n",
        "# define the models, list sizes, and metrics\n",
        "#list_sizes = [10, 20, 50, 100]\n",
        "list_sizes = [10,20]\n",
        "metrics = [\"recall\",'recall_reranking',\"ndcg\", \"ndcg_reranking\", ## UPDATE\n",
        "           \"c-equity\",\"c-equity_reranking\", \"u-parity\",\"u-parity_reranking\"] ## UPDATE\n",
        "\n",
        "# initialize a dictionary to store results with mean and standard deviation\n",
        "results = {\n",
        "    \"iters_num\": {model: 0 for model in [\"bnslim\", \"fslr\", \"bnslim_admm\", \"fairmf\"]},\n",
        "    \"fit_time\": {model: 0 for model in backbones.models.keys()},\n",
        "    \"reranking_sample_users\": {model: 0 for model in backbones.models.keys()}, ## UPDATE\n",
        "    **{metric: {model: {size: {\"mean\": 0, \"std\": 0} for size in list_sizes} for model in backbones.models.keys()} for metric in metrics},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e147392",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Context Engineering Elements Recommender System\n",
        "Define modular functions/classes for each context element."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5312ca13",
      "metadata": {},
      "source": [
        "|Modelo| ($) input | ($) Cached input | ($) Output | Ref.\n",
        "|---|---|---|---|---|\n",
        "| gpt-4.1-nano | 0.10 | 0.025 | 0.40 | https://platform.openai.com/docs/models/gpt-4.1-nano\n",
        "| gpt-5-nano | 0.05 | 0.005 | 0.40 | https://platform.openai.com/docs/models/gpt-5-nano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e99ef139",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt-4.1-nano\"\n",
        "#MODEL_NAME = \"gpt-5-nano\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "215b63a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
        "os.environ['LANGSMITH_PROJECT'] = \"ml-agentic-recommender\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "915f6957",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_im = im_train # The interaction matrix to use in tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5ad85f",
      "metadata": {},
      "source": [
        "## CMem - Memory Structure\n",
        "\n",
        "> Memory ID: An experiment number (experiment_id). Can be a fixed value. Same value for user and system space.\n",
        "\n",
        "### User space (namespace for memory)\n",
        "* Level 1: user_id\n",
        "* Level 2: the \"memories\" (e.g. user preferences, recommended items, ...)\n",
        "\n",
        "**User's memories:**\n",
        "* \"preferences\": avoid request preferences multiple times for the same user.\n",
        "* \"recommendations\": avoid repeat some already recommended item for the user.\n",
        "\n",
        "\n",
        "### System space (global state):\n",
        "* Level 1: \"system\"\n",
        "* Level 2: \"counter\" # Count how many request are done in the system\n",
        "\n",
        "### System space -- Metrics\n",
        "* Level 1: \"metrics\"\n",
        "* Leve 2: \n",
        "    * \"c-equity\": exposure metric for C-fairness\n",
        "    * \"u-parity\": coverage metric for C-fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f3628d5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_id = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf59a7f",
      "metadata": {},
      "source": [
        "## CTools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa1a330f",
      "metadata": {},
      "source": [
        "### Get User History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "02fb96f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool, ToolRuntime\n",
        "\n",
        "@tool(\"GetUserHistory\",description=\"Get the history of items of the user from the oldest to newest watched movie.\")\n",
        "def get_user_history(user_id:int) -> str:\n",
        "        \n",
        "    print(f\"[GetUserHistory] user_id: {user_id}\")\n",
        "    logger.info(f\"[GetUserHistory] user_id: {user_id}\")\n",
        "    inner_user_id, inner_item_ids = next(base_im.users_in([user_id]).binary_item_history)\n",
        "    \n",
        "    raw_user_id = get_raw_user_ids(ratings_pp,[inner_user_id])[0]\n",
        "    raw_item_ids = get_raw_item_ids(ratings_pp,inner_item_ids)\n",
        "\n",
        "    movies_id_title = movies.loc[movies.Item_id.isin(raw_item_ids),['Item_id','Title']].drop_duplicates()\n",
        "    movies_id_title.Title = movies_id_title.Title.apply(lambda x : original_to_updated_titles[x])\n",
        "    movies_id_title['User_id'] = raw_user_id\n",
        "\n",
        "    return ', '.join(pd.merge(movies_id_title,ratings,on=['User_id','Item_id']).sort_values('Timestamp').reset_index(drop=True)[['Title']].values.reshape(-1))\n",
        "\n",
        "#get_user_history({\"user_id\":0})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d41d5d4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"GetNotInteractedItemsByTheUser\",description=\"Get all items from the catalog which the user has not interacted with.\")\n",
        "def get_non_interacted_items(user_id:int) -> list[int]:\n",
        "    \n",
        "    logger.info(f\"[GetNotInteractedItemsByTheUser] user_id: {user_id}\")\n",
        "    inner_user_id, inner_item_ids = next(base_im.users_in([user_id]).binary_item_history)\n",
        "    all_inner_item_ids = set(base_im.active_items)\n",
        "    non_interacted_inner_item_ids = list(all_inner_item_ids - set(inner_item_ids))\n",
        "    raw_not_interacted_item_ids = get_raw_item_ids(ratings_pp,non_interacted_inner_item_ids)\n",
        "\n",
        "    return '; '.join(movies_items.loc[movies_items.Item_id.isin(raw_not_interacted_item_ids),'Title'].apply(lambda x : original_to_updated_titles[x]).values)\n",
        "\n",
        "#get_non_interacted_items(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c1d3d9",
      "metadata": {},
      "source": [
        "### Filter candidate set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "127a88c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"FilterCandidateSet\",description=\"Get the filtered items from the backbone recommender model to compose the candidate set for recommendation.\")\n",
        "def get_user_candidate_set(user_id : int, top_k : int = 20, backbone_model_name : str =\"ease\") -> str:\n",
        "    \n",
        "    print(f\"[FilterCandidateSet] User[{user_id}], Model: {backbone_model_name}, Top K: {top_k}\")\n",
        "    logger.info(f\"[FilterCandidateSet] User[{user_id}] - Model: {backbone_model_name}, Top K: {top_k}\")\n",
        "\n",
        "    return ', '.join([ item['item_title'] for item in backbones.get_candidate_items(user_id, backbone_model_name,top_k) ])\n",
        "\n",
        "#get_user_candidate_set({\"user_id\":0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "62d9a2d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def collaborative_filtering(im,user_id,num_sim_users, num_items):\n",
        "    # TODO: Fazer filtragem colaborativa comum\n",
        "    similarity_matrix = im.binary_values @ im.binary_values.T\n",
        "    sim_mat = similarity_matrix.toarray()\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "960de577",
      "metadata": {},
      "source": [
        "### Generate User Preferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "81fcfc62",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.messages import HumanMessage, SystemMessage, ToolMessage\n",
        "from langgraph.types import Command\n",
        "from langchain.agents import AgentState\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from typing import List\n",
        "\n",
        "class UserContext(BaseModel):\n",
        "    user_id: int\n",
        "    session_id : int\n",
        "\n",
        "class RecommenderAgentState(AgentState):  \n",
        "    preferences: str\n",
        "    recommended_items: List[str]\n",
        "\n",
        "@tool(\"GetUserPreferences\",description=\"Infer the user preferences based on the user history of watched movies.\")\n",
        "def get_user_preferences(user_history:str, runtime:ToolRuntime[UserContext,RecommenderAgentState]) -> str:\n",
        "\n",
        "    # # Context\n",
        "    # if runtime.context:\n",
        "    #     print(f\"[GetUserPreferences - context] Context: {runtime.context}\")\n",
        "\n",
        "    print(f\"[GetUserPreferences] User[{runtime.context.user_id}] history length: {len(user_history)}\")\n",
        "    logger.info(f\"[GetUserPreferences] User[{runtime.context.user_id}] history length: {len(user_history)}\")\n",
        "    if(len(user_history.strip())==0):\n",
        "        logger.warning(f\"[GetUserPreferences] No User[{runtime.context.user_id}] history available.\")\n",
        "        return \"No user history available. Preferences cannot be inferred.\"\n",
        "    \n",
        "    # Memory\n",
        "    namespace_for_memory = (str(runtime.context.user_id),\"preferences\")\n",
        "    if runtime.store:\n",
        "        user_memory = runtime.store.get(namespace_for_memory,experiment_id)\n",
        "        if user_memory is not None:\n",
        "            user_prefs = user_memory.value['infered_preferences'] or None\n",
        "            if user_prefs is not None: # Using already generated preferences\n",
        "                logger.info(f\"[GetUserPreferences - Memory] User[{runtime.context.user_id}] Using existent preferences found in memory.\")\n",
        "                return Command(update={\n",
        "                    \"preferences\": user_prefs,\n",
        "                    \"messages\":[\n",
        "                        ToolMessage(\n",
        "                            user_prefs,\n",
        "                            tool_call_id=runtime.tool_call_id\n",
        "                        )\n",
        "                    ]\n",
        "                })\n",
        "\n",
        "    # New inference of preferences\n",
        "    system_msg = SystemMessage(\"You are a movie recommender specialist, tell me what are my preferences and explain them.\")\n",
        "    preferences_msg = HumanMessage(f\"The movies I have watched (watched movies): {user_history}.\\n\\nWhat features are most important to me when selecting movies (Summarize my preferences briefly)?\")\n",
        "\n",
        "    messages = [\n",
        "        system_msg,preferences_msg\n",
        "    ]\n",
        "\n",
        "    model = init_chat_model(MODEL_NAME)\n",
        "\n",
        "    response = model.invoke(messages)  # Returns AIMessage\n",
        "    \n",
        "    # Storing inferred preferences in the Memory\n",
        "    preference_memory = {\"infered_preferences\":response.content}\n",
        "    runtime.store.put(namespace_for_memory, experiment_id, preference_memory,index=False)\n",
        "    logger.info(f\"[GetUserPreferences - Memory] User[{runtime.context.user_id}] inferred preferences stored in memory.\")\n",
        "    # Tool response\n",
        "    return Command(update={\n",
        "        \"preferences\": response.content,\n",
        "        \"messages\":[\n",
        "            ToolMessage(\n",
        "                response.content,\n",
        "                tool_call_id=runtime.tool_call_id\n",
        "            )\n",
        "        ]\n",
        "    })\n",
        "\n",
        "#get_user_preferences(\"Moral Kombat, Fast and Furios\")\n",
        "# model = init_chat_model(MODEL_NAME)\n",
        "# model_with_tools = model.bind_tools([get_user_preferences])\n",
        "# response = model_with_tools.invoke(\"My watch history is Moral Kombat and Fast Furios. What are my preferences \")\n",
        "# print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942c9d80",
      "metadata": {},
      "source": [
        "### Check Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c48e5ff5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'protected'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_user_group(user_id):\n",
        "    if user_id in inner_uids_m:\n",
        "        return \"non-protected\"\n",
        "    elif user_id in inner_uids_f:\n",
        "        return \"protected\"\n",
        "    else:\n",
        "        return \"undefined\"\n",
        "\n",
        "get_user_group(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fea4a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Expected output format\n",
        "class RecommendationResponse(BaseModel):\n",
        "    \"\"\"A list of recommended movies for the user.\"\"\"\n",
        "    user_id : int = Field(description=\"The user id of the generated recommendation list.\")\n",
        "    recommendations: List[str] = Field(description=\"A list of recommended movie titles\")\n",
        "\n",
        "def get_final_recommendation_list(recommended_titles : List[str]) -> List[str]:\n",
        "    # Normalization of titles\n",
        "    recommended_titles = [title.strip() for title in recommended_titles] # Response normalization\n",
        "    available_in_original_title_lower = [title.lower() for title in original_to_updated_titles] # Normalize titles from the original catalog\n",
        "    available_in_updated_title_lower = [title.lower() for title in updated_to_original_titles] # Normalize titles from the updated catalog (cleaned titles)\n",
        "\n",
        "    final_recommendations = []\n",
        "\n",
        "    # Check if recommended titles are in the catalog\n",
        "    for title in recommended_titles:\n",
        "        lower_generated_title = title.lower()\n",
        "        if lower_generated_title in available_in_original_title_lower:\n",
        "            final_recommendations.append( original_to_updated_titles[[t for t in original_to_updated_titles if t.lower() == lower_generated_title][0]] )\n",
        "            continue\n",
        "        elif lower_generated_title in available_in_updated_title_lower:\n",
        "            final_recommendations.append( [t for t in updated_to_original_titles if t.lower() == lower_generated_title][0] )\n",
        "            continue\n",
        "        else:\n",
        "            # If the title is not found in either catalog, stop and ask for new recommendations\n",
        "            raise ValueError(f\"The recommended movie `{title}` are not available in the catalog.\")\n",
        "    \n",
        "    return final_recommendations\n",
        "\n",
        "@tool(\"CheckRecommendations\",description=\"Get a list of recommended movies and check if they are available in the catalog.\")\n",
        "def check_recommendations(result:RecommendationResponse, runtime: ToolRuntime[UserContext,RecommenderAgentState]) -> str:\n",
        "    \n",
        "    print(f\"[CheckRecommendations] User[{runtime.context.user_id}] - Recommendations length: {len(result.recommendations)}\")\n",
        "    \n",
        "    final_recommendations = []\n",
        "    try:\n",
        "        final_recommendations = get_final_recommendation_list(result.recommendations)\n",
        "    except ValueError as ve:\n",
        "        logger.warning(f\"[CheckRecommendations] {ve} for the user[{runtime.context.user_id}].\")\n",
        "        return f\"{ve}. Please recommend another movie.\"\n",
        "\n",
        "    \n",
        "    # Update memory with new recommended items\n",
        "    namespace_for_memory = (str(runtime.context.user_id),\"recommendations\")\n",
        "    if runtime.store:\n",
        "        user_memory = runtime.store.get(namespace_for_memory,experiment_id)\n",
        "        if user_memory is not None:\n",
        "            user_previous_recs = user_memory.value.get('recommended_items',[])\n",
        "            logger.info(f\"[CheckRecommendations] User[{runtime.context.user_id}] already has recommendations: {user_previous_recs}\")\n",
        "            \n",
        "            for title in final_recommendations:\n",
        "                if title not in user_previous_recs:\n",
        "                    user_previous_recs.append(title)\n",
        "                else:\n",
        "                    logger.warning(f\"[CheckRecommendations] Title {title} already in recommended_items for user[{runtime.context.user_id}].\")\n",
        "            \n",
        "            runtime.store.put(namespace_for_memory, experiment_id, {\"recommended_items\": user_previous_recs, \"user_group\": get_user_group(runtime.context.user_id)}, index=False)\n",
        "        else:\n",
        "            # First time recommendations for the user, storing them in the memory\n",
        "            logger.info(f\"[CheckRecommendations] Storing first recommendations for User[{runtime.context.user_id}]: {final_recommendations}\")\n",
        "            runtime.store.put(namespace_for_memory, experiment_id, {\"recommended_items\": final_recommendations, \"user_group\": get_user_group(runtime.context.user_id)}, index=False)\n",
        "    else:\n",
        "        logger.warning(f\"[CheckRecommendations] There is no memory in the recommendation for the user[{runtime.context.user_id}]\")\n",
        "     \n",
        "\n",
        "    # Return the final recommendations\n",
        "    return Command(update={\n",
        "        \"recommended_items\": final_recommendations,\n",
        "        \"messages\":[\n",
        "            ToolMessage(\n",
        "                f\"All recommended movies are available in the catalog. They are added to the memory.\",\n",
        "                tool_call_id=runtime.tool_call_id\n",
        "            )\n",
        "        ]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2ecc3d",
      "metadata": {},
      "source": [
        "## CState"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9722f14",
      "metadata": {},
      "source": [
        "#### Original metrics calculation (from Fair Neighborhood backbone models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "82dd624c",
      "metadata": {},
      "outputs": [],
      "source": [
        "available_in_updated_title_lower = [title.lower() for title in updated_to_original_titles] # Normalize titles from the updated catalog (cleaned titles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "d99f7405",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_metrics(user_id,recommendation_list, K, model_name=\"ease\"):\n",
        "    \n",
        "    final_recommendations = []\n",
        "    try:\n",
        "        final_recommendations = get_final_recommendation_list(recommendation_list)\n",
        "    except ValueError as ve:\n",
        "        logger.warning(f\"[GetMetrics] {ve} for the user[{user_id}].\")\n",
        "        return {}\n",
        "\n",
        "    # map recommended titles back to original titles in the dataset and get their inner ids in the backbone matrix\n",
        "    original_recommended_titles = [ updated_to_original_titles[recommended_movie] for recommended_movie in final_recommendations]\n",
        "    recommended_raw_item_ids = backbones.get_raw_item_ids_from_titles_in_catalog(original_recommended_titles)\n",
        "    recommended_inner_item_ids = get_inner_item_ids(ratings_pp,recommended_raw_item_ids)\n",
        "\n",
        "\n",
        "    # generated_predictions = backbones.predictions[model_name].copy() # With copy, does not change the original matrix\n",
        "    generated_predictions = backbones.predictions[model_name]\n",
        "    max_val = generated_predictions[user_id].max() # Get the greatest relevance score generated by the backbone for the user\n",
        "    # generated_predictions[resp.user_id,:] = -np.inf # Mask all items (need to check) \n",
        "    generated_predictions[user_id,recommended_inner_item_ids] = max_val + 0.5 # Force the reranked recommendations to have a greater score than backbone predictions\n",
        "\n",
        "    cequity_mean, cequity_std, _ = c_equity_at_n(generated_predictions[inner_uids_f, :], generated_predictions[inner_uids_m, :], inner_genre_dict, K)\n",
        "    #print(f\"Reranking With: {model_name} | C-Equity@{K}: {cequity_mean:.4f} (±{cequity_std:.4f})\" )\n",
        "\n",
        "    # Coverage\n",
        "    females = np.ones(base_im.num_active_users); females[inner_uids_m] = 0\n",
        "    # Reranked\n",
        "    uparity_mean, uparity_std = u_parity_at_n(generated_predictions,females, inner_genre_dict, K)\n",
        "    #print(f\"Reranking With: {model_name} | U-Parity@{K}: {uparity_mean:.4f} (±{uparity_std:.4f})\" )\n",
        "    return {\n",
        "        \"c-equity-mean\": cequity_mean,\n",
        "        \"c-equity-std\": cequity_std,\n",
        "        \"u-parity-mean\": uparity_mean,\n",
        "        \"u-parity-std\": uparity_std\n",
        "    }\n",
        "\n",
        "#get_metrics(resp.user_id,resp.recommendations,10,\"ease\") # `resp` is generated after agent invoke"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5ac024",
      "metadata": {},
      "source": [
        "### Reranking Metrics (fairness metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "6c63780d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import after_agent\n",
        "from langgraph.runtime import Runtime\n",
        "from typing import Any\n",
        "\n",
        "# Runs after the agent completes its execution (a reranking/recommendation is made)\n",
        "@after_agent(state_schema=RecommenderAgentState)\n",
        "def calculate_metrics(state: RecommenderAgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    result : RecommendationResponse = state['structured_response']\n",
        "\n",
        "    # c-fairness == consumer fairness (c-equity and u-parity)\n",
        "    c_fairness_metrics = get_metrics(result.user_id,result.recommendations,10,\"ease\")\n",
        "\n",
        "    recommender_counter = 1 # If memory fails, always overwrite with the last values at counter `1`\n",
        "    # Get/Update System \"STATE\"/MEMORY (metrics calculation)\n",
        "    if runtime.store:\n",
        "        ## Get/Update recommender counter\n",
        "        system_namespace = (\"system\",\"counter\")\n",
        "        system_memory = runtime.store.get(system_namespace,experiment_id)\n",
        "        if system_memory is not None:\n",
        "            recommender_counter = system_memory.value.get('recommender_counter',0)\n",
        "            recommender_counter += 1\n",
        "            \n",
        "        runtime.store.put(system_namespace, experiment_id, {\"recommender_counter\": recommender_counter}, index=False)\n",
        "        logger.info(f\"Generated Recommendation: {recommender_counter}\")\n",
        "    \n",
        "    ## Store the metric @ this point (recommender counter)\n",
        "    namespace_for_cequity = (\"metrics\",\"c-equity\")\n",
        "    namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "\n",
        "    #if recommender_counter % 5 == 0: # Calculate every 5 recommendations\n",
        "    print(f\"Metrics@{recommender_counter}: C-Equity: {c_fairness_metrics['c-equity-mean']:.4f} (±{c_fairness_metrics['c-equity-std']:.4f}), U-Parity: {c_fairness_metrics['u-parity-mean']:.4f} (±{c_fairness_metrics['u-parity-std']:.4f})\")\n",
        "    \n",
        "    runtime.store.put(namespace_for_cequity,recommender_counter,{\n",
        "                                                                 \"user_id\": result.user_id,\n",
        "                                                                 \"mean\": c_fairness_metrics['c-equity-mean'], \n",
        "                                                                 \"std\": c_fairness_metrics['c-equity-std']\n",
        "                                                                }, index=False)\n",
        "    runtime.store.put(namespace_for_uparity,recommender_counter,{\n",
        "                                                                 \"user_id\": result.user_id,\n",
        "                                                                 \"mean\": c_fairness_metrics['u-parity-mean'],\n",
        "                                                                 \"std\": c_fairness_metrics['u-parity-std']\n",
        "                                                                }, index=False)\n",
        "        \n",
        "    return {\"messages\": \"Recommender state updated.\", \"jump_to\": \"end\"}\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "22bad46b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Action', 'Drama']"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_movie_genres(movie_title):\n",
        "    original_title = updated_to_original_titles[movie_title]\n",
        "    return movies_items[movies_items.Title == original_title]['Genre'].values[0]\n",
        "\n",
        "get_movie_genres(\"Seven Samurai (The Magnificent Seven) (Shichinin no samurai)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "11bb1842",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.store.memory import InMemoryStore,BaseStore\n",
        "\n",
        "def format_item_distribution(items_distribution:dict) -> str:\n",
        "    non_protected_dist = \"## Non-protected group items distribution:\\n\"\n",
        "    if 'non-protected' in items_distribution:\n",
        "        non_protected_dist += \"\\n\".join( [ f\"* {category}: {items_distribution['non-protected'][category]}\" for category in items_distribution['non-protected']] )\n",
        "    else:\n",
        "        non_protected_dist += \"There is no distribution for non-protected users group. No one user from this group get recommendation.\"\n",
        "\n",
        "    protected_dist = \"## Protected group items distribution:\\n\"\n",
        "    if 'protected' in items_distribution:\n",
        "        protected_dist += \"\\n\".join( [ f\"* {category}: {items_distribution['protected'][category]}\" for category in items_distribution['protected']] )\n",
        "    else:\n",
        "        protected_dist += \"There is no distribution for protected users group. No one user from this group get recommendation.\"\n",
        "    \n",
        "    return protected_dist + \"\\n\\n\" + non_protected_dist\n",
        "\n",
        "def get_item_distribution(store:BaseStore):\n",
        "    # Get all users with recommendation\n",
        "    namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "    u_parity_items = store.search(namespace_for_uparity)\n",
        "    users = set([item.value.get('user_id') for item in u_parity_items])\n",
        "    # For each user with recommendation, get the recommended items and the user group\n",
        "    categories_distribution = dict()\n",
        "    for user in users:\n",
        "        # User Group\n",
        "        user_group = get_user_group(user)\n",
        "        if user_group not in categories_distribution:\n",
        "            categories_distribution[user_group] = dict()\n",
        "\n",
        "        # Recommended items\n",
        "        namespace_for_user = (str(user),\"recommendations\")\n",
        "        user_item = store.get(namespace_for_user,experiment_id)\n",
        "        if user_item is None:\n",
        "            logger.warning(f\"[get_item_distribution] No recommendations found for user[{user}].\")\n",
        "            print(\"Sem recomendações para o usuário:\", user)\n",
        "            continue\n",
        "\n",
        "        user_recommended_items = user_item.value.get(\"recommended_items\")\n",
        "        \n",
        "        # Categories of recommended items\n",
        "        for movie in user_recommended_items:\n",
        "            movie_categories = get_movie_genres(movie)\n",
        "            for category in movie_categories:\n",
        "                if category not in categories_distribution[user_group]:\n",
        "                    categories_distribution[user_group][category] = 0\n",
        "                categories_distribution[user_group][category] = categories_distribution[user_group][category] + 1\n",
        "        \n",
        "    return categories_distribution\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "03e209d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"GetCurrentState\",description=\"Get the current state of the recommender based on the target metric.\")\n",
        "def get_current_state(runtime: ToolRuntime):\n",
        "    print(\"[GetCurrentState] --->>>\")\n",
        "    logger.info(f\"Getting system state for the user {runtime.context.user_id}\")\n",
        "    if runtime.store:\n",
        "        # System\n",
        "        system_namespace = (\"system\",\"counter\")\n",
        "        system_memory = runtime.store.get(system_namespace,experiment_id)\n",
        "        recommender_counter = 0\n",
        "        if system_memory is None:\n",
        "            print(\"[1] Primeira recomendação sem system memory\")\n",
        "            return \"It is the first recommendation.\"\n",
        "        else:\n",
        "            recommender_counter = system_memory.value.get('recommender_counter',0)\n",
        "            if recommender_counter == 0:\n",
        "                print(\"[2] Primeira recomendação com system memory\")\n",
        "                return \"It is the first recommendation.\"\n",
        "        \n",
        "        # u-parity\n",
        "        namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "        u_parity_item = runtime.store.get(namespace_for_uparity,recommender_counter)\n",
        "        u_parity = u_parity_item.value.get(\"mean\")\n",
        "        print(f\"[State] Com u-parity: {u_parity}\")\n",
        "        categories_distribution = get_item_distribution(runtime.store)\n",
        "        formated_categories_distribution = format_item_distribution(categories_distribution)\n",
        "        return f\"Current u-parity: {u_parity}.\\n\\n# Categories distribution\\n{formated_categories_distribution}\"\n",
        "    else:\n",
        "        print(\"\\t Sem memória\")\n",
        "        return \"It is the first recommendation.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3246cc59",
      "metadata": {},
      "source": [
        "## CInst (System Instruction) - Agent Orchestration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc31b66",
      "metadata": {},
      "source": [
        "**WITHOUT FAIRNESS**\n",
        "You are a movie recommender specialist.\n",
        "\n",
        "To recommend movies, you follow the steps:\n",
        "1. Get the user history of watched movies.\n",
        "2. Filter a candidate set of movies for the user.\n",
        "3. Based on the user history, always get the user preferences.\n",
        "4. Recommend 10 movies from the candidate set based on the users' preferences. The output should be a list of 10 movie titles only, without any additional text.\n",
        "5. Check if the recommended movies are available in the catalog. If any movie is not available, recommend another movie from the candidate set and replace the wrong one.\n",
        "6. If all recommended movies are available, output only the list of 10 movie titles and stop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93ac4dd",
      "metadata": {},
      "source": [
        "# You are a fair movie recommender specialist.\n",
        "\n",
        "To recommend movies, you follow the steps:\n",
        "1. Get the user history of watched movies.\n",
        "2. Filter a candidate set of movies for the user.\n",
        "3. Based on the user history, always get the user preferences.\n",
        "4. Recommend 10 movies from the candidate set based on the users' preferences. The output should be a list of 10 movie titles only, without any additional text.\n",
        "   * Check the system state to be fair based on the target metric. Use the tool `GetRecommendedItemDistribution`.\n",
        "5. Check if the recommended movies are available in the catalog. If any movie is not available, recommend another movie from the candidate set and replace the wrong one.\n",
        "6. If all recommended movies are available, output only the list of 10 movie titles and stop.\n",
        "\n",
        "\n",
        "## Target Metric\n",
        "You must use the u-parity metric to be fair.\n",
        "The User-coverage Parity metric (u-parity) measures the disparity between the proportions of users from protected (Gp) and non-protected (Gnp) receiving recommendations from an item category, averaged across all categories. Scores range from 0 to 1, with 0 indicating that equal percentages of users (from both groups) receive recommendations from each item category and 1 indicating a rare scenario where each item category covers users from only one group.\n",
        "u-parity helps identify if there is an imbalance in how different user groups are covered by recommendations across categories.\n",
        "\n",
        "The protected group (Gp) is composed of women, and the unprotected group (Gnp) is composed of men."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "357b397d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.structured_output import ToolStrategy\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.store.memory import InMemoryStore \n",
        "from langchain.agents.middleware import ToolRetryMiddleware\n",
        "\n",
        "model = ChatOpenAI(model=MODEL_NAME)\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "# You are a fair movie recommender specialist.\n",
        "\n",
        "# Instructions\n",
        "To recommend movies, you follow the steps:\n",
        "1. Get the user history of watched movies.\n",
        "2. Filter a candidate set of movies for the user.\n",
        "3. Based on the user history, get the user preferences.\n",
        "4. Recommend 10 movies from the candidate set based on the users' preferences. Check the current system state to be fair based on the target metric. Use the tool `GetCurrentState` to get the state.\n",
        "5. Check if the recommended movies are available in the catalog. If any movie is not available, recommend another movie from the candidate set and replace the wrong one.\n",
        "6. If all recommended movies are available, output only the list of 10 movie titles and stop.\n",
        "\n",
        "Run each step one time, except if you need recommend another movie to replace a wrong one.\n",
        "\n",
        "## Target Metric\n",
        "You must use the u-parity metric to be fair.\n",
        "The User-coverage Parity metric (u-parity) measures the disparity between the proportions of users from protected (Gp) and non-protected (Gnp) receiving recommendations from an item category, averaged across all categories. Scores range from 0 to 1, with 0 indicating that equal percentages of users (from both groups) receive recommendations from each item category and 1 indicating a rare scenario where each item category covers users from only one group.\n",
        "u-parity helps identify if there is an imbalance in how different user groups are covered by recommendations across categories.\n",
        "\n",
        "The protected group (Gp) is composed of women, and the unprotected group (Gnp) is composed of men.\n",
        "\n",
        "The target u-parity is: 0.05.\n",
        "\n",
        "# Output Format\n",
        "The output should be a list of 10 movie titles only, without any additional text.\n",
        "\"\"\"\n",
        "\n",
        "tools = [get_user_history,get_user_candidate_set,get_user_preferences,get_current_state,check_recommendations]\n",
        "\n",
        "checkpointer = InMemorySaver() # Unused\n",
        "store = InMemoryStore() # In-memory store for context and state / memory - Instantiate once per experiment\n",
        "\n",
        "# Agent with all components of the recommender system in Context Engineering paradigm\n",
        "agent = create_agent(\n",
        "    model,\n",
        "    middleware=[calculate_metrics, ToolRetryMiddleware(\n",
        "            max_retries=3,\n",
        "            backoff_factor=2.0,\n",
        "            initial_delay=1.0,\n",
        "        )], # Cstate / Metrics\n",
        "    tools=tools, # Ctools\n",
        "    context_schema=UserContext, # Context control by user ID\n",
        "    system_prompt=system_prompt, # Cinst\n",
        "    response_format=ToolStrategy(RecommendationResponse), # Response format\n",
        "    state_schema=RecommenderAgentState, # Last Recommendation\n",
        "    checkpointer=checkpointer, # Unused\n",
        "    store=store # Cmem / Cstate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c68de2d",
      "metadata": {},
      "source": [
        "## CQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec87f273",
      "metadata": {},
      "source": [
        "## SEM FAIRNESS\n",
        "\n",
        "f\"Recommend movies for the user {user_id}\"}\n",
        "\n",
        "\n",
        "## COM FAIRNESS\n",
        "\n",
        "f\"Recommend movies for the user {user_id}. The user is in {group}.\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b1a451",
      "metadata": {},
      "source": [
        "### Experiment setup (users to test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "feb29494",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3153"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users_to_test = backbones.im.num_active_users\n",
        "users_to_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "3818d7de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "# Prompt[0]: Recommend movies for the user 0. The user is in non-protected group.\n",
            "[GetUserHistory] user_id: 0\n",
            "[FilterCandidateSet] User[0], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[0] history length: 4033\n",
            "[GetCurrentState] --->>>\n",
            "[1] Primeira recomendação sem system memory\n",
            "[CheckRecommendations] User[0] - Recommendations length: 10\n",
            "Recomendações OK\n",
            "Metrics@1: C-Equity: 0.0411 (±0.0426), U-Parity: 0.0735 (±0.0542)\n",
            "\n",
            "# Prompt[1]: Recommend movies for the user 1. The user is in protected group.\n",
            "[GetUserHistory] user_id: 1\n",
            "[FilterCandidateSet] User[1], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[1] history length: 1650\n",
            "[GetCurrentState] --->>>\n",
            "[State] Com u-parity: 0.07350999760119094\n",
            "[CheckRecommendations] User[1] - Recommendations length: 10\n",
            "Recomendações OK\n",
            "Metrics@2: C-Equity: 0.0409 (±0.0425), U-Parity: 0.0731 (±0.0542)\n",
            "\n",
            "# Prompt[2]: Recommend movies for the user 2. The user is in protected group.\n",
            "[GetUserHistory] user_id: 2\n",
            "[FilterCandidateSet] User[2], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[2] history length: 258\n",
            "[GetCurrentState] --->>>\n",
            "[State] Com u-parity: 0.07314248565705277\n",
            "[CheckRecommendations] User[2] - Recommendations length: 10\n",
            "Recomendações OK\n",
            "Metrics@3: C-Equity: 0.0409 (±0.0424), U-Parity: 0.0728 (±0.0545)\n"
          ]
        }
      ],
      "source": [
        "RETRY_ALLOWED = 3\n",
        "\n",
        "users_with_recommendations = []\n",
        "\n",
        "for user_id in range(0,3):\n",
        "    n_try = 1\n",
        "    while n_try < RETRY_ALLOWED:\n",
        "        try:\n",
        "            config = {\"configurable\":{\"thread_id\": f\"experiment_{experiment_id}\",\"user_id\": user_id}}\n",
        "\n",
        "            print(f\"\\n# Prompt[{user_id}]: Recommend movies for the user {user_id}. The user is in {get_user_group(user_id)} group.\")\n",
        "            result = agent.invoke(\n",
        "                {\n",
        "                    \"messages\": [{\"role\": \"user\", \"content\": f\"Recommend movies for the user {user_id}. The user is in {get_user_group(user_id)} group.\"}],\n",
        "                },\n",
        "                config=config,\n",
        "                context=UserContext(user_id=user_id,session_id=experiment_id)\n",
        "            )\n",
        "            users_with_recommendations.append(user_id)\n",
        "            break # If successfull, continue to the next user.\n",
        "            #print(result['messages'][-1].pretty_print())\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"[Users loop] - Problem generating recommendation for the User[{user_id}]: {e}\")\n",
        "            n_try += 1\n",
        "            if n_try >= RETRY_ALLOWED:\n",
        "                logger.error(f\"[Users loop] - Error: it was not possible generate recommendation for the user[{user_id}]: {e}\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "a5055114",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users_with_recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d1041ae",
      "metadata": {},
      "source": [
        "# Calculate final result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "6424bd05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "u-parity@1 0.0731907836425877\n",
            "u-parity@2 0.0731907836425877\n",
            "c-equity@1 0.04092017234772063\n",
            "c-equity@2 0.04092017234772063\n"
          ]
        }
      ],
      "source": [
        "# u-parity\n",
        "namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "metric_items = store.search(namespace_for_uparity)\n",
        "uparity_list = []\n",
        "for metric in metric_items:\n",
        "    print(f\"u-parity@{metric.key}\" , metric.value['mean'])\n",
        "    uparity_list.append(metric.value)\n",
        "\n",
        "# c-equity\n",
        "namespace_for_cequity = (\"metrics\",\"c-equity\")\n",
        "metric_items = store.search(namespace_for_cequity)\n",
        "cequity_list = []\n",
        "for metric in metric_items:\n",
        "    print(f\"c-equity@{metric.key}\" , metric.value['mean'])\n",
        "    cequity_list.append(metric.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "bd4a37d2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['system', 'counter'], key='1', value={'recommender_counter': 3}, created_at='2025-12-18T02:19:50.107125+00:00', updated_at='2025-12-18T02:19:50.107129+00:00', score=None)]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "store.search((\"system\",))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "9acffed3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['2', 'preferences'], key='1', value={'infered_preferences': \"Based on your movie list, your preferences indicate a diverse but somewhat distinctive set of traits:\\n\\n1. **Classic and Cult Films:** You enjoy iconic classics and cult favorites like *Star Wars: Episode VI - Return of the Jedi*, *A Fish Called Wanda*, *Monty Python and the Holy Grail*, and *The Wrong Trousers*, suggesting an appreciation for humor, satire, and films with memorable cultural impact.\\n\\n2. **Humor and Whimsy:** Several comedies and lighthearted films such as *St. Elmo's Fire*, *A Fish Called Wanda*, *Harvey*, and animated comedies like *A Grand Day Out* point to a love of humor—ranging from witty and satirical to absurd and slapstick.\\n\\n3. **Dramas and Emotional Depth:** Movies like *Forrest Gump*, *Auntie Mame*, *Eat Drink Man Woman*, and *The English Patient* reflect an interest in emotionally resonant stories, character-driven narratives, and films that explore human relationships and personal growth.\\n\\n4. **International and Artistic Flair:** Your selections include internationally flavored films (*Eat Drink Man Woman*, *Walkabout*, *The English Patient*), indicating an appreciation for diverse cultural perspectives and more artistic, visually rich storytelling.\\n\\n5. **An Eye for Visual and Artistic Style:** Films like *A Room with a View* and *The English Patient* showcase an inclination toward visually beautiful and artistically crafted movies.\\n\\n**In summary:** You gravitate toward a mix of iconic classics, humorous and whimsical films, emotionally compelling stories, and visually/artistic movies, with an openness to international cinema and a taste for both lighthearted and deeply moving narratives.\"}, created_at='2025-12-18T02:28:29.173935+00:00', updated_at='2025-12-18T02:28:29.173938+00:00', score=None),\n",
              " Item(namespace=['2', 'recommendations'], key='1', value={'recommended_items': ['Casablanca', 'Babe', 'Airplane!', 'Shakespeare in Love', 'The Princess Bride', 'Back to the Future', 'Star Wars: Episode IV - A New Hope', 'Stand by Me', 'Raiders of the Lost Ark', 'Wallace & Gromit: The Best of Aardman Animation'], 'user_group': 'protected'}, created_at='2025-12-18T02:28:30.619032+00:00', updated_at='2025-12-18T02:28:30.619036+00:00', score=None)]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "store.search((\"2\",))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "52f17f21",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result = pd.DataFrame(uparity_list,columns=['mean','std']).rename(columns={\"mean\":\"u-parity\", \"std\":'u-parity_std'}).join(pd.DataFrame(cequity_list,columns=['mean','std']).rename(columns={\"mean\":\"c-equity\", \"std\":'c-equity_std'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ccaa814",
      "metadata": {},
      "source": [
        "## Metrics understanding\n",
        "\n",
        "### u-parity:\n",
        "The User-coverage Parity metric measures the disparity between the proportions of users from protected (Gp) and non-protected (Gnp) receiving recommendations from an item category, averaged across all categories. Scores range from 0 to 1, with 0 indicating that equal percentages of users (from both groups) receive recommendations from each\n",
        "item category and 1 indicating a rare scenario where each item category covers users from only one group.\n",
        "\n",
        "u-parity helps identify if there is an imbalance in how different user groups are covered by recommendations across categories.\n",
        "\n",
        "### c-equity: \n",
        "\n",
        "The Consumer-side Equity (c-Equity) measures the ratio of the observed probability of recommending an item category to protected\n",
        "users (Gp) relative to that of non-protected users (Gnp). For convenience, as c-Equity is computed separately for each item category,\n",
        "we reformulated it as the absolute difference between the observed probabilities, averaged across all categories.Scores range from 0 to 1, indicating the average difference in\n",
        "the visibility of item categories between two user groups. A score of 1 indicates a rare scenario where Gp exclusively gets recommendations from one item category and Gnp from a different item category, with no overlap.\n",
        "\n",
        "c-equity helps identify if there is an imbalance in how item categories are recommended to distinct user groups.\n",
        "\n",
        "### Both\n",
        "\n",
        "Smaller values represent a more balanced fairness score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "5062b79b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Fairness metrics in Reranking'}, xlabel='Iteration', ylabel='Score'>"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_result[['u-parity','c-equity']].plot(xlabel='Iteration', ylabel='Score', title='Fairness metrics in Reranking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "id": "5f5436d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result.to_csv(\"ml-agentic-recommender-variant1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc7ee50",
      "metadata": {},
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "4fcfb8a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GetUserHistory] user_id: 2\n",
            "[FilterCandidateSet] User[2], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[2] history length: 258\n",
            "[CheckRecommendations] User[2] - Recommendations length: 10\n",
            " --- GetMetrics --- [2]@10 (backbone_model=ease)\n",
            "Metrics@3: C-Equity: 0.0409 (±0.0425), U-Parity: 0.0732 (±0.0544)\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: RecommendationResponse\n",
            "\n",
            "Returning structured response: user_id=2 recommendations=['Casablanca', 'Babe', 'Airplane!', 'Shakespeare in Love', 'The Princess Bride', 'Back to the Future', 'Star Wars: Episode IV - A New Hope', 'Stand by Me', 'Raiders of the Lost Ark', 'Wallace & Gromit: The Best of Aardman Animation']\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "user_id = 2\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Recommend movies for the user {user_id}. The user is in {get_user_group(user_id)} group.\"}],\n",
        "    },\n",
        "    config=config,\n",
        "    context=UserContext(user_id=user_id,session_id=experiment_id),\n",
        "    \n",
        ")\n",
        "\n",
        "print(result['messages'][-1].pretty_print())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "8149e561",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Item(namespace=['1', 'recommendations'], key='1', value={'recommended_items': ['Babe', 'Star Wars: Episode IV - A New Hope', 'Lady and the Tramp', 'Vertigo', 'North by Northwest', 'To Kill a Mockingbird', 'Star Wars: Episode V - The Empire Strikes Back', 'Psycho', 'Blade Runner', 'The Graduate'], 'user_group': 'protected'}, created_at='2025-12-04T17:50:36.311931+00:00', updated_at='2025-12-04T17:50:36.311933+00:00')"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_memory = (str(user_id),\"recommendations\")\n",
        "store.get(namespace_for_memory,experiment_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "178654a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_memory = (str(2),)\n",
        "store.search(namespace_for_memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "db5189b4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['metrics', 'c-equity'], key='1', value={'user_id': 0, 'mean': 0.04092017234772063, 'std': 0.04246618579515752}, created_at='2025-12-04T17:50:24.432208+00:00', updated_at='2025-12-04T17:50:24.432209+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='2', value={'user_id': 1, 'mean': 0.04092017234772063, 'std': 0.04246618579515752}, created_at='2025-12-04T17:50:39.833384+00:00', updated_at='2025-12-04T17:50:39.833385+00:00', score=None)]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_memory = (\"metrics\",\"c-equity\")\n",
        "store.search(namespace_for_memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e15311",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all users with recommendation\n",
        "namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "u_parity_items = store.search(namespace_for_uparity)\n",
        "users = [item.value.get('user_id') for item in u_parity_items]\n",
        "# For each user with recommendation, get the recommended items and the user group\n",
        "categories_distribution = dict()\n",
        "for user in users:\n",
        "    # User Group\n",
        "    user_group = get_user_group(user)\n",
        "    if user_group not in categories_distribution:\n",
        "        categories_distribution[user_group] = dict()\n",
        "\n",
        "    # Recommended items\n",
        "    namespace_for_user = (str(user),\"recommendations\")\n",
        "    user_items = store.search(namespace_for_user)\n",
        "    user_recommended_items = user_items[0].value.get(\"recommended_items\")  # WARN: user_items[0] -> only first recommendation per user\n",
        "    \n",
        "    # Categories of recommended items\n",
        "    for movie in user_recommended_items:\n",
        "        movie_categories = get_movie_genres(movie)\n",
        "        for category in movie_categories:\n",
        "            if category not in categories_distribution[user_group]:\n",
        "                categories_distribution[user_group][category] = 0\n",
        "            categories_distribution[user_group][category] = categories_distribution[user_group][category] + 1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "76dd9971",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'non-protected': {'Action': 2,\n",
              "  'Drama': 7,\n",
              "  'Romance': 2,\n",
              "  'War': 2,\n",
              "  'Crime': 3,\n",
              "  'Thriller': 3,\n",
              "  'Comedy': 1,\n",
              "  'Film-Noir': 1},\n",
              " 'protected': {\"Children's\": 2,\n",
              "  'Comedy': 2,\n",
              "  'Drama': 5,\n",
              "  'Action': 2,\n",
              "  'Adventure': 2,\n",
              "  'Fantasy': 1,\n",
              "  'Sci-Fi': 3,\n",
              "  'Animation': 1,\n",
              "  'Musical': 1,\n",
              "  'Romance': 2,\n",
              "  'Mystery': 1,\n",
              "  'Thriller': 3,\n",
              "  'War': 1,\n",
              "  'Crime': 1,\n",
              "  'Horror': 1,\n",
              "  'Film-Noir': 1}}"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "54711866",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['system', 'counter'], key='1', value={'recommender_counter': 3}, created_at='2025-12-04T17:22:10.479493+00:00', updated_at='2025-12-04T17:22:10.479497+00:00', score=None)]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_system = (\"system\",)\n",
        "store.search(namespace_for_system)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d5bc5b5e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAFNCAIAAAARix00AAAQAElEQVR4nOydB3xT1fv/n5vVtCmddEFLB7MMZYuA8JUlKLIUF0umgKDwB1myZAnIqCJ7iKDI3oqAypIh68dqgVJKoXvvJm2a5P8kt03TkqRNm5vcm5y3r1e8uSv05pNznnHOcwQqlQoIBAsiAALBshDNESwN0RzB0hDNESwN0RzB0hDNESyN/WouNVYefi07LVGmkKvkRSpFkZ6YEU8AymLd9wBKzQZfBQpKz035AAr1/ykeqJRluymBSlVM6b257pkqHlDKCueolDoXCsQgEvHFEr5fsGPbnm7ATSh7i8/FPym8eCw1M7lQqVDxBZRIzHOU8ClKJS/UpzkhpZSX7ad4lEqpeYs/1WI9N9dqtOxMej+fwo/TezLFp1Slh3g8SqlUlT+Hpywuk6HQgY+3LSxUFhYoiuUqkQPfN1jcb5wfcAo70lxmcvHBdbFymdLVS9Sio+srb7gAxzl/IC36QZ40r9gnwPH9KXWBI9iL5g6ti098Jg1o6NR/Qh2wLTJTFSe3xOVlKTr3r92iMwd+SHahuW1fP+MLqZELg8B2ibyV/8/+pLr1nd5lfVdr+5rbsSDGt5747dG+YAdsn/e81Zuurbux2r2wcc1tnh1dr5Gkz0gfsBu2z3/m7u0waBJ7TQge2C47FsbUa+BkV4JDRi8KTk8q/HtfKrAVm9Xc79uSQKnqYx9dagXGLgl+fCOnWA7sxGY1F/Mwb8SCYLBX6jWR7PwmGliJbWpu97cvPPzEfD7YLX3H+BbKlPcuZQP7sE3NZacVvfeFP9g3gU0kN85kAPuwQc2hJefoJBCJwJLMmjXr2LFjYDo9e/aMj48HBug7xk+ar4BCYBs2qLmEZzL/hmKwLBEREWA6iYmJmZmZwBhiJ/7pfcnAMmxQc0WFitZvegIzXL58+bPPPuvcufOAAQMWLFiQlpaGO9u2bZuQkLB48eL//e9/+DYvL2/Tpk0jRoygT1u7dq1MJqMv7969+2+//TZ27Fi85MKFC++++y7u7N+//7Rp04ABPHwdkp7LgGXYmubio6QUgFeAEBjg0aNHX375Zbt27Q4ePDhjxozIyMiFCxeCRoj4Om/evPPnz+PG3r17d+7cOWzYsLCwMDz/7NmzW7Zsoe8gFAqPHDnSuHHj9evXd+rUCU/Andgpr169GhjAL0hcJFUCy7C18XMJUTJMrQIz3LlzRywWjxo1isfj+fr6Nm3aNCoq6uXThg4diu1ZcHBJpObu3btXrlz54osvcJuiKFdX1+nTp4NFqFNfcucig3139bA1zeVkynmMhUhatmyJveSUKVNee+21Ll26BAQEYBf58mnYmF29ehV7XmwIi4vV4+k8PDy0R1GpYCk8fUQKBevaOZuz5yhsS5jKIDdp0uSHH37w8vJat27dwIEDJ06ciG3Yy6fhUexM8YSjR4/evHlz5MiRukdFlvSo+UqKYt1XbGuac6olVBQz1bciHTt2RLvtxIkTaMllZ2djm0e3ZFpUKtWhQ4c+/PBD1Bz2v7gnNzcXrER2soJi8GFUE1vTnG+QuFjOVG9y69YttMxwA5u6vn37orOJesJ4h+45crlcKpV6e3vTb4uKii5evAhWIu5pAcU+0dma5oKbOapUkJvJSPeKPSm6q4cPH8ag2oMHD9A/RfH5+fk5ODigyK5du4Y9KboXQUFBx48fj4uLy8rKWrRoEVqBOTk5+fn5L98Qz8RXdGzxbsAAidEFIjHpW5lHKOLdOJMGDIAOKfaYq1atwuTBuHHjJBIJ2m0CgdoPQ2f2xo0b2PJhI7ds2TJ0b99//30MzrVv337SpEn4tkePHhjDq3BDf39/DNFhMA9NQGCAtIRCLz/LJmSqgA2O2TyyPiE3Uz58biDYPT9Ojfp4RqCnHyPRympjg+1cj499s9OLwO75e0+KUMxjm+DAJudU1/LgOToLDq2Le2+y/qEl2LS/+eabeg8pFAo0yAzZ3Rj7cHNjZKoBRpvRBdZ7CL0QDPjp/Sc1atRIm+F4mSd3c5u9zsaJEbY5HyItVr537fNJaxoYOuFl06oq1KnD4CQDQ/8kzN46OzvrPYRaRCdG76GLB9PCr2dPWFkf2IfNzsH57btYDJoMm2OnVt3Gr56+/WmdwGaOwD5sdmz6x18FyPIUV0+yLttoAXZ+E+NdT8xOwYFtz/sauyzk/y5kpDxXgD2xb1UcxaPem8zeUhK2P6d6w/SnXQf6NOvkDHbAriUv3LyE/T5j9VR+u6gdsXFmtE9dh0FfcKaKTPXYsSAGsw5DZ9cDdmMvNXJ+mv9cXqxo3c2zbQ9XsDmObUqIe1JQv0Wt3p9yYAK5HdUCu/Z75u1z6WjrBDZx7jXMR8C6WKnJxD4qvPJHSlp8IcYjh80KErLUZ6iI3dU8vHg47dHN3CKpgi+kxE68Wh4Oklp8dKWKi8pcDR4P48ag+2C0NQz5Ap6iWEm/xdOUypKjFKgqbGMMl+KDkr4rpblCc4K2LiKfTyk01Q4FIj5+uuZCvKFKHf6lNB+uVF+I/w71vwfU5TiFDjyFHApyFPl5xdLcYjzJxUP4xoDagaFOwB3sTnNaLh9Lj3taIMtXFstVSoWqWLeeJqX+jkFXc+rnpM4E8DQyot9q9KA5iqdSVMm2ujorTyNZpSZ3QEcG1GfTJ/D5mO3QbPCAHsPLF1CKYpX6ZIqu81pyaxWtONC8U/9HCR3wKh4abS61hUGhEk5Um3sZ+9Uc00ybNq1fv35du3YFQnlI3XSmKC4upoc5ESpAHgpTEM0ZgjwUpiCaMwR5KExBNGcI8lCYgmjOEOShMAXRnCHIQ2EKojlDkIfCFHK5XCjkfn6NAYjmmIK0c4YgD4UpiOYMQR4KUxDNGYI8FKYgmjMEeShMQXwIQxDNMQVp5wxBHgpTEM0ZgjwURjBeg8LOIZpjBGzkiDFnCKI5RiAdqxHIc2EEojkjkOfCCERzRiDPhRGI5oxAngsjYECYaM4Q5LkwAmnnjECeCyOoVCrtEhGEChDNMQKfz09KSgKCPojmGAE71gprMhG0EM0xAtGcEYjmGIFozghEc4xANGcEojlGIJozAtEcIxDNGYFojhGI5oxgy+tDWBEeT/1glUqmVi/mNERzTEGaOkMQzTEF0ZwhiD3HFERzhiCaYwqiOUMQzTEF0ZwhiOaYgmjOEERzTEE0ZwiiOaYgmjMEWQfHzLRu3VqzzFK5p9qzZ88VK1YAQQOJz5mZNm3agCYPocXb23vEiBFAKIVozswMGzbMxaXc0m8tWrRo2rQpEEohmjMzXbp00VUY6u+jjz4Cgg5Ec+YHe1IPDw96u3HjxnRvS9BCNGd+2rdv36xZM9xwcnLCrhYI5bFTv/Xmmcz0ZHmRTB3L0K5BDVTJasGUZpFqiqdZwZfSvC29kMenlApVyZn0SCWqbHVh7RrUOTk59x/cdxQ7qt1YnuYMZdlN6E/UrmjN41FKZelBzbmUZqHsstvyVUpFxVJ2jhJh/RbOwS04siC6DnanuXP70iJv51B89SrnRVK1arTLTUPZ16peFLpETFTJDhqKp15/WrPwuWbtciivOe1i6LTK1PemgKe5m85NSi7hqT8DhVv2DwDNx770oeo7KCtqTiTmy4sUIgf+qAWBwAcOYV+ae3K74NzBlO4f1fEOFIFNcP1UZuTtrHFLgvnc+YPsSHN3z+dd+yP1k6+DwbZ4dk929ffEz5Zz5u+yIx/i9vmMek2dweYIfkUsFFNnd6cCR7AjzckK5E3bu4It4uLhkBwnBY5gRzl+9ChFEk4Z21VGpVIUFXBmvo8daQ4dTq1TaWOoFKDgzhwzMpbJFkA/UMWdaY32pTnKRn10jCFT3LHM7UtzKhtdlwYbOdLOESwKxacoPmfacKI5W0ClQM+VM204secIlobYc7YApRnnwhXsSXMqm23mVCrgUNrcnjRHqWw108fjqwf2AUews74VbBOlsnTYKRcgPoQtoB7dzB17zr7mQ1jdhxg5+oOw75cbP+fQ4b09er0GpkByXwSCMYjmCJaGaM4gR47u3/3LtpXLf/x63tT09LTAwOBpU7/Oysr8dvn8YkVxu7av/7+pc9zc3PHMgoKCNWHL7ty5mZubExQY0qdP/wH9B9M3iYmJXr5iwfMXz1q2bDt86Bjd+2dkpG/YuOZB+F2ZTNau3et4NCAgEKoFt3L8ZH6rQYRCYV5e7s5dm1et3HDi2Hm5XL5s+fxTfx7ftnXvr7uP3X9wZ9/+3fSZs+Z8kZAQt3jR6v17/+jSpfv3P6x4+CgcNCsHz5w92cvLZ+eOg5+N/WLvvl2oXfoShUIxddpnd+7emjplzo5t+9zdPCZ+PiI+IQ7sAKI5Y6BoRgwfh82Po6Pja+07JSbGT50y28fH18PDs+WrbZ4+jcRzrv13+f79O19NmxfapJmrq9uQT0a2aNHy511b8NDFS/+kpCR/PnEaXhIUFPLF5BkoYvrOeMmLFzFzZi9+rX1HvNuE8VNcXN0OHdoD1YJb40rsSHMYTqiG34p9Jb3h5OTk7u6B+qDfOjo65eXn4cazZ1FisTg4uL72kkYNQx8/jsCN+PhYPOTr60fv9/Ss7e3tQ29jM4ntaOtW7ei3FEWhiO/euw3VQp37IuPnWAhVrVAJpZPIpPQlNbG7FIvLTaZHdUqlBaCezZ+N0tQ95OAgpjewwcNG9M3ubXWP0tZhNSG5L5bCwBcjkUhksnJzrvIL8mt7eoG6KJMrLT4tBQX59Aa2edhfL12yVvcon1fNKUIqikspFuK31pTGjZqi4/kk6nHDBo3pPQ8fPgjSdLW+Pn54KDo6KiSkAb6NiopMSyuZhVq/fiOpVOrt7Vu3jj+9JyEx3s21mu0cBVwaV0J8iJrSvn3HOnX816xZ+uhxBIY/tu/YgJr7cLC6HFPHjl1FItGqNUtQeai2RUtmY8tHX9WmdXu8cNWqxcnJSdnZWUePHRg/Ydiffx6HakHGptsXAoFgyaLVmzaHYbADFRYS0nDxolXouuIhZ2fnZUvDtmz5oW+/ruhMjBv7xV9/n9Je+O3SsOMnDqEQIyLuo2vco0efQYPsojqiHdUr+XHqk4GTQ1w8bXBa9antcdnp8rFLuVGyhLRzNoHamCNjmdiHDbfnxJ5jKTY6F0INmVPNUlQqisypZgP21M5RKp6tjhNW577IfAhWYrMmHaXi0Lh74rfaAiolpeJOmTOiOYKlIZojWBqiOVuAJ+DxhcSHIFgQZbFSISc+BIFgAKI5gqWxl/FzixYtAkrJ49tmrX6RI8/BkTN/mo1r7vTp0ydOnMCN0aNHC0WilJh8sEWkeQpHZ35GRoZMJgPWY8t967///nvx4sUZM2bgdt26dd2948KvZYa0lIDNkZMuD0/Zt/XDf4RCoUAg4PP5IpHI2dnZUcN3330HbMIGx2z+9ddfBw4c2Lx5c0FBgZNTuWlXm2c+C23t0aq3Ta3AdDDshdiJCnj9+dKlS1NTU5WaxUnwa0Xl4TZu/N//wxoQGQAAEABJREFU/R+wCZvSHD5xLy+vFStWjBgxwtfXV+852+fGODgK/EOdPX1FxfJi3UM8HuguJlO2lrD2sE49S0qzkmvZQbQWyxZ51SzISq/+q7M2a7mFYst2lnwFuksXa2ZFqnSvUZUsZ1y2wacEcVF5CdEFQc2cenzsjXuWL19++PBhZfkFcW7evAksw0Y0FxERgX1oWFhYgwYNKj35yI8JaUmFiiJVsbzc11OyMHXZ+/KDAiijYwSol5YEfmlbKy+VzmA+7XHtp+se1ayRTZXbWXoBdqEOEl6DlrXeGOBBH0G1DR48+Pnz59qrsXs9f/48sAzOa+7q1auvv/76hQsXmjRp4uPjA9UCzb5bt25NnToVzMc777zTp0+fSZMmgTmYM2fO+PHj69WrZ/y0S5cuLV68GJ0J0JREqV27NtoYISEhwCY47LcWFhb27t07NjYWt7t27VptwSFSqdS8gtu3b19mZua5c+fS0tLAHCxbtuzOnTvKyhaSe+ONNzp16kRv+/v7nz17lq49gP47sAZOam7//v34XRYXF//6668ffPAB1AC0gfD1rbfeAvOBvgvaVUVFRfHx8cePV3PK6sv069cPNff3338bP23evHmBgYHYfdFBouBg9WQwdCMWLFgA7IB7msNniiaLh4eHRCLx9PSEGrBmzRpsKcHcoNdMG1X4q8AGJj/fbEFBjIOcOXPmxYsXRs7h8XiHDh1CU0F356xZsz799FPQWBHYAINV4Yw9t2fPnry8vHHjxmE/iDEnqBmoA5RsSkqKt7c3mBW0pdDwio6Opt86ODhMnjz5o4/MOVn6xo0boaGh6B+A6cTExIwdO3bnzp0YsAQrwY12Dn+1ycnJ9C+15oLDLu/LL7/EDbMLDjS/DV3PEY3Oo0ePmveH3a5dO7wtmoxgOkFBQWjk0du///47WANWaw6/Lbrva9myJdr4GFsHc4DG1rZt24AZMDaBDqPuHuwK8Q8Bs4JGBd42ISEBqgXdyF2/fn3lypVgcVjatz59+rR+/froImDAyVxSQ06ePNm3b19gkl69eqGriLJDYw5NfnxFZyIgIODIkSNgbrBBResNbw7VBe+ADge2fO3bt3d1tVB6hnXtXHh4eIcOHfCrwu0hQ4aYUXDY2OTk5ADDoI2PfgPm37Ap2r1795UrVzATwITgEJQLynrLli1QXfAO+Iphv0GDBmEWBywCWzSHzS0dVsAWAnPzjRs3BnODabFPPvkELAX+IehmAsPQosnOzoYagE8bQzDYPKNr9eeffwLDsEJz+GPFtp2OXr7yyitm/6pmz56Nr9pgqWXAZtUyviH68vjoMGIMNQOTFk5OTviDX79+PTCJNe05bAmwX+jevXvDhg0pxupEzp8/f8yYMZVmjbhOZGQkhuXoX1cNwdQO2ojo1Xbu3JkJI8867ZxcLsdXdJowfNWoUSOGBEfHLPBrsIrgunXrZgHzUUsjDZUmx6oC7ZRgAuO9997LysoCc2Ppdg4fyrp169BFmDZtGjDJ/fv3MUWGCW+wEpj6RH+i5tFEk8Bv89SpU2+//TaYCbQUsYFAN8iMCRvLtXNon6LgMECPaSumBQeaYL0VBQeaIR4WFhxohkth+2TGgcHYt6IDjkbejh07wExYqJ377bffNm/efO7cOYr5+t6YCbCkf8pCUCJoioFZiYuL8/f3R5Pxrbfeql7aTQuz7Rymk2/fVq/tgr8VDNBbQHA//fQTtqNgbWhPHKwELbiaxO1eBgWHrw0aNMCgOqa8oQYwqDmM7n7wwQe044PRebAIbdq0YWKoiKmgDSQUCsGqdO3adfXq1WBWXn31VWw7sG+MiYlBaxWqhfk1h+Fs7EZBMzAakyqYwgLmwZz3559/DprwHrAA9McvX74MVgUjvf369QMGwDAe+rYXLlzYu3cvmI45NYeJRXydMGECPRiaDpFbhrlz59KjLwm6YOATSkPi5oXP5y9durRLly6gMaBNGiNoHs3l5uYuWrQoIkK9mN/Bgwd79uwJluLu3bv4ip5arVq1gDVkZGRYzJyoFExUmNe201KnTh3QhAbfeeedCqNpjFBTzdHTPQ4fPtxSA1gWdNBYOK8J2GHPacHoycCBA4Ex2rZtS38LaMFXxcirfqwE47oLFy50cXGhJ8pbBYz61nA+hF3x/vvvYy8EjIFNHWYa0Y0bNGiQkdOqozls20QiETrMt27dspaTuHHjRjQcgWAK6N5hOzRkyBBgkuTkZB8fn59//nno0KF8fUWJTO5b0VGYOnUqdhxeXl7WEtyxY8fMOK6OCR48eMCeeVZa8CvDpg4Yhp70ia+GOsDqjBpCtxRjAWA9MJ+Ynp4OLAbzLvSUC7aRmJiILZAFfg/oR3bo0EHvIa7O48eencfjWVf6XOThw4fLli3bvXs3WA+T+1a0Eyud1msBsItH/xzYBz6f7du3A1sJCgqyTKeP+dmxY8fqPVQdew7dVbA2mFLDsJPVY/0vs2TJEiamMJoLR0fHqpQRqjkY1jA0edvkvhU19+2337LQQGYD2OMnJCRYJt1XPTBPahl7Dtt7zBS4ubm9fMjkdg4dRvYI7tKlS5GRkcAa8AeMnRewGPxVREVFAfNglESv4IC79hwNfsEzZ84EdoDJmLCwMD67y2QTe66mBAQEYJ43JSUFWABGyOfMmQPshthzBEtD7DnzsHTp0uvXr4P1wGzPpk2bgAsQe848DB48GH+7YD1mz57dsWNH4AJssOdM7lvxh9KrVy90GIGgobCwUC6X13Baiu2Bnfj06dP1DmMxuZ3DNrNHjx7AMnJycsLDw8EaxMbGVliFgs2gFL755htgHnTvDBVcswV7DnFxcVm7dm3Na3aYCn7of//9h5lf4AjEnjMn8+fPN15o1+xkZWVhmovp4WjmhdhzBJvF9u05moiIiF27dtHbb7/99vDhw4ExMALM0MQWRiH2nJlp2rTp77//3rt37zZt2mDMjNGZYHPnzjVvNXTLQOw5M9O/f/8nT56kpaXRK2sxOhz11KlT6LgA1yD5VrPRt2/fVq1axcfHa11IlB09x9vs4G2tm/aoCWzIt9qIPXfy5El8lLoNG24zVIpr1qxZnFgOWi/EnjMnBw4cQEtOqzNs55iYLZGYmDho0CC6ZgIXIfacmcFk//jx4+mh4djOmaXQaQX8/PzMXtrNkrDBnjN5riFtz3Xv3h0sS04qJL0oUCqLyxZ2pjd4FJQt7wxtGr3rPbbVkSOHk5OSJYoGj27klC3ai78vrQi1e/n4M9LuLF1IWnvP0v3qpXtBdeP69SK5vFz99fILCQv5wvqtLV1b0yTI+LkqEXE1/8rJ1CK5AjVTLNeVQvnFxw2tFK3dp7NMuRYen1IqXj614uUqzQfpPaQLX8QDhUriKhw+j6Vl2tkwfs7kds7C9lzS86KLR5KbdPBs091CKwPVlCL451DSppnR41ewa3VoGmLPVcKjGwXHNsUN+TqEM4JDRNDtY9/O7/ptnhUN7IPE5yrhysmUoKYsqipXdQJbOIol/GObEoFlkPhcJRTmK9r29AJu4hPolBFfCCyDDfE59tpzuRkK9B1FrPYCjYHBwUJ5VUtPWgxizxlDqa54z8n6PTTFSlDIgW0Qe45gaYg9R7A0xJ4zBg/j1cBhMHhMsW+aBLHnjKEEFeMrNTEJ/mBU5s/31hRiz9kymCuj2PejIfacMTgzfc8A6kQ2++rmEnvOGCrtCzehWNnQEXvOGKXjk7gKK5s5Ys8RLA6x54zBdXsOWOlDEHvOGOyLM5gGO80CYs8ZwyrfWXR01Jvd296/b4ZaO8Sesxd7buB7PRMS44FgAGLPVYaJ7URSUmJWViYQDEPsOWNopnaZcH58QtzQYQNwY8jQ/p06dV2yaDVu79q97fSZk2lpKd7evi1fbTN1ymx6on9BQcGasGV37tzMzc0JCgzp06f/gP6DK9wwNy/3p52b/rv2b2ZWRuNGTXv06PPO2wOq/M8Bnjo+B2yD2HPmpG4d/2+XhuHGr78cowWHijl6bP+Ez6YcPHB69KiJ5y+cPXDwV/rkWXO+SEiIW7xo9f69f3Tp0v37H1Y8fFSxTOfKld9EhN+bMmX2zh0HQ0Obrw37Njz8HlQZFaViYSlEYs8Zg1ezLAS2Ur/t/XnY0DGdO/+vlnOt/3XtMXDAh7/8ul0ul1/77zJ6CV9NmxfapJmrq9uQT0a2aNHy510VC3vdvXcb5diubQdvb59xYyev/3Gnp6cJA+Uxwa9k3TBhYs8ZRVUz1zU29jnKC9sn7Z5GjULz8vLi42OfPYsSi8XBwWWrcjVqGPr4cUSFO6AQ9x/4ZeOmsCtXLuKtGjcK9fX1A46Dzc/3338PzMNJe66GZGSk4avYQazd4+iorjQtlRakp6eJxeXmWTg5OeH+CneYOWPh8eMH/zl3GpXnLHEeOPDD4cPGCgTVWWWZPeTm5t68eROYh7v51uojkaiL50tlUu2egoJ8fPXwqC2RSGQ6+5H8gvzaL/WbLrVchg4ZtX3r3h/CtqGTsfuX7YeP7IUqQ6mLDIDdwkl7robfV/36jfCnFh5+V7vn4cMHaNh5eXmjEyqTyZ5EPdY9FBRcbgHM7Jzsw0f24WkURWEnO3HC1FYt20Y+eQRVh+KxMPcVGhpqmUWquRmfM/0LC6gXhK/nz5+NePgAW6mePd7+5dcdaI3l5OacOfP7kaP73n9/CMZK2rfvWKeO/5o1Sx89jsjISN++YwNq7sPBw3RvJeAL0KtYuGjmgwd38Ry8/EnUoxbNW0KVUZf55Hr+rgZw054zfWg6hkt6v/UuhkiaN3t17ZrNn0+chgpbvHQO/uZQZJ98PPLjj0bgaWiTYTBl0+awiZ+PwD8nJKTh4kWrsDHTvRX2v4sWfrdu/XeTvxyNb9HhGP/ZlD69+wHHefjw4bJlyyzQ1Bmx50yuy4T23Pnz5y1QCyw7U/HzouiRCxsCN7n2R2rkzZzPV7NrzWqLaQ7tOUx4bN269eVDLLbn1CY4141w1iX52WDPmdy3Wsye47rcMAnB49uv44r23E8//aT3EHvrCXN6ciuoC1+wMQ+BfeuwYcOAebBtMrQ+B6vzrVyXnT2D9tzIkSP1HmL1+Dk7DqkyhSXtOcx56D3EXnuOSI7TcNKe43i5EvVPhse+Xw2x54zCdWtOZdf2KDftOYrzvSsL5+AQe84oKuK4chhO2nMUUJzundhZl4nYc8ZQqZP8pF4JV+FqfM6uvzRmIPacMVBufAEfOAufTwlFnC+6Um04ac+5evCBp5JmAUeR5iqFDqyzDYg9VwmOzoLrZ1KAm6TGSn3rScBe4ao912+0f2xkHnCQS0czihWqPqNYt3AUG+w5tq/fmp+t+GXZ8zoNnF/r5e3oBuwn6VnRrb9SczKKxi0LBjsG+8OCggK93avJmrM8SbGKUzviZHkK9aQWRdm0Fnq94LK3Ks1y0vqO6h4qvx/oscja+ds6GyWnaa8t3VOyaLCqZM1Ez8AAAA19SURBVLlizWrZpSdTfIrP57l7iT6c7g+sxGJj041gst9qsfkQWnwD+CMXBAK96pzuKEjtktFa1ZRKTkWptaAtm1h2pHygOWxdWPu27Tp21Kx1rip/qnYhde3NKc0enQ+ltGW2S3ei4ezsAQTQ2HPz5s3T67qarDnanrOk5rTU8jBz6KSgMMXBudi1NocjMqZC7DkrU1hYKBAIsHECgrnhtj1HMCNssOdsp/5cNZg6dert27eBwACczbcyTH5+PtgZxJ6zMjKZDFN5PBaWw+Q+xJ4jlEDsOSuDBsfTp0+BwADEntMP2nMUC8fyMgmx56wM2nMODg72JjvLQOw5QgnEnrMyAwcOTE9PBwIDEHtOP2hwcL0OuqmQ+RBW5sSJE46OjkBgACPzIYg9Z18Qe87KdOvWDf8cIDAAsef0gwaHvQ1kIvaclbl48SIQmIHYc4QSiD1nTTDx1atXLyAwA7Hn9CCXy5VKu1scidhz1sTNze2PP/4AAjMQe45QAiftOeySTp8+DdwnOTl55syZYGfweDzLrI0eHx8/f/58vYdM1pxQKHR3d//888+B46xfv37GjBlgZzRu3Ngy49AOHz7ctGlTvYeq2bdmZGSgAV67dm0gcI3s7GyZTObj4wNWoprTTzw8PHJycgwtXMdyrl+/jr9CsFdcXV3fe++9wsJCYAyUNZouho5Wf8pTSEjI8OHDExMTgVNg3GjDhg2DBg0CO+brr7++ceMGMAaaXkbaoxr5rehP4D+9Y8eOQCCUEhsbe/LkyQkTJhg6oaaxEmyiMaCPXS1wgXPnzgUGBmILDXbPqVOnmjdvjlE0sDg1nU7s4OBw9OjRjRs3AuvZv3//zZs3ieBoJBLJ2rVrwdxg+mHHjh3GzzHDyOxRo0ZdunQJ7SR/f5YW+gPNs8D0CVfaYwvQpUsX0HRT2GqA+dizZ0+lFTnsJQ9x9erV9u3bk7JfTHPx4kV8zmKx2Mg5ZivVgX5Kz549gZVMnToV2zkiuApIpdIxY8aAWcHm07jgwIyaw+TE1q1bWRj3wk7/yy+/fOONN4BQHkdHx7p165pxoMOqVavu3btX6Wk23rcWFRXl5uZ6enoCQR+YTMKAl1lMOkywTpw48dixY5Weaf4yWMuWLbt27RqwA2ze3Ny4UOLfSmDKH01+NDygxnh7ex86dKgqZ5pfc3PmzPnrr78w+wHW5vTp0/izI2accTDm8O2330KNycrKquIEdTJ+jgBo765evbomJQ1OnDhx+/btKo5YYarEZHh4+Lp168BK3Lp1a/r06UCoGt9//30Na2hERER8+umnVTyZKc01a9YM8yoHDhwAi6A7nk+hUGBqBH0oIFSNvLy8GnqvM2fOxKRiFU+2UN86cODA6OjoPn36LF++HBhgwIABiYmJ//33HxCqxaRJk4YOHdqhQwcwnevXr6MDERQUVMXzGS/fvGbNmt69e8fGxqIt/+LFC2AAtCQKCgqweWvVqlW3bt3Onj0LBBOZPXt29cpoYGB52rRpVRccWEBz2M2lpaWBxi3HUFlCQgKYG4z60m4yyjonJ8csXpi9gcHhTp06gek8f/58w4YNJl3CrObatGmDLZD2LQqCiZrRjx490v2N4qdgyg8IJnLmzJmqRHQr0KRJkxYtWph0CYOaw26ugrGI7dzDhw/B3Dx+/Fh3djRue3l5jRo1CgimgO0cGkImXYLRic2bN4OJMKi5f/75B81SX19f3ais2TWHqZukpCR6XRGUOBqzmHuYO3dupaO4CBWQSCTYzqF9VvVLtmzZ0rx5czARxv1WDE9j4v/48eMpKSn49wQHB5t3HEBkZOSUKVPw5ti2hYaGfvTRR6RjrTYoBsyDCYXCqpyM9gxa6tWYP1Z9zRVJ4e99SUkxRbICuUKhUinVK+uql2tWla6mq4FexLnks9R/FMWjNOtDl52mXfm5worQutfCS0sEl91cpXOG7p9WtlIwxVN/Fn4gRYklgsBQp+4fegFBH0OGDJk/f37jxo0rPZO2oauRWqyO5u5dzLnxV4Y0X8EX8BwkDhJXByc3B5FEoMIeTlG2vDiNsrT/LtGY5rBWO5oDJVt6FijXLA1Ny65MopqFpimNolS8sp06d6z4b8Cngj8Kab48Lz0/P1smlxajWmu5id4a7usTKAKCDmgRYSS1KuPq0IZBt6MaBZlN05y8CH5e9KyoUOXk7hjUyhs4S5FUFXc/UZpTVMtdMHxuVQPoBC2XLl1CB2L8+PFgOiZo7tzetIjrWc5ezoEtbadjenotXppX1HtYnQYtnYCgAeMAYrG46rksU6mq33pia+KjWznNegbbkuCQ+h3qBrXyO707MfxqDhA0ODk5oVtm5ASMwGO+C6pLlTR3endKbKQ0tJtt9kHOnuJmPYLOH0q9/6/1x/yxgYCAgLFjx2J2x9AJGMZLTU2F6lJ533pkQ2LKC1njrvXA1gn/+1nHt2u36kbGFRsDgym7du2qSci9knbuweXc+Kf59iA4pNmbwZdPpgFBw8qVK/UO9hYIBDXM8VSiuYtHUwKa+4GdwANXb+ctc54BAaB27dq//vrry/vXrl1bw3pcxjR3ICxO4CBw9a1kuqItEfCql6IYLh0hix3CiBEjunfvXmHnlStXYmJi3N3doQYY01xKrCz4Vbtp5Erx9HcNv0acCXWC4eVsBLoXS5cuhZphUHPHNycKRHyhM0snTd25/9f0ea/l5Zu/6KJ3Q1elEu5dIKETuH//foUivqg5Z2dnqBkGNZf0XFbLq6Z35ygOTsK7/2aB3UMPjMPOlH67adOmPXv2QI0xONunUKpoFGqnVYxc/VxSoogDq2b9+vXabcyu/vbbb1Bj9GvuxplsvoACxoh5ce/MuW2xcRHOEvfQxp17vTlGLJbg/svXDpy9sGPCqI279s5OTon282nQpePH7Vr3pa86+ee6m3f/cBA5tXrlLe/aDIZvagc6J0WmFuaCQy0gYMqBHh5mrkFo+vtWjMnpjiIyL2npsZt3TpbLCyeN2zbikxWJyU827pigUKjLF/AFQqk09+jvqz4YMOe7Rddead5t/9ElmVlJeOjK9UNXrh8c9M5XX372k6d7nbPntgOTYKA84gbxJNRgOh+bN8zoV1pYroro11x+TjGPz9QQ4tt3/xTwhZ9+vMLHK8jXO2Rw/6/jEx8/eHiBPqpQyHu+OSYwoAVFUW1bvoNpkvjESNz/79X9rzTrjip0cnLBlq9BSFtgEj6fykotAgLA6NGjo6OjMUQskUjAHOgXlkKupBgbtY4da4B/U4mkJMXk4e7n6eH/7Pkd7Qn16jajN5wcXfBVKstF5aVlxPp4B2vP8a/TBJiFKiq0uxXo9OLm5ta6deuvvvoKzIR+e07owJcWMPXEpbK82PgIjHTo7szJLQvDUi9167LCfKVS4eBQNtxIJDJ5qKBJ4D+BL2TQouUWffr0AfOhX3NiJ35uJlML1deq5Rkc2PKtbuN0d0okrkYuETtIeDy+XC7T7iksKgBmoVw9yRBiRtCvOU8/UfILGTBDHZ+Gt+7+ERLUip6shSSlRHt5GvNDseVzd/OLeXG/a+m034ePLwOTKBXKwMZkFCcj6LfaWnR0URQzNR8Mwx9KpfL4qbVFRbKU1OcnT/+4+sdPEpOjjF/1avMe9yPOYfoBt/+5tOt53ANgjNwUGfat3mSqBDPo15y7r4jHp9JjcoEB0PGcPmmPSOgYtmnEyh8+iI65PXjA15X6BD26jnytTf+jf6xGQxAbuX591ANZGZoomR6X4yghlRKZwuCYzX2r43KzlA061gX74/GFF41au7z5AalCzAgGIyI9P/EtksrB/shLk6ExRwTHHAbzrR5+AomrIOZWclAb/RO1s7KTV/34id5Djg7O0sI8vYd8vUImjdsK5mPu0u6GDmFug8/X8wcGBbQYMzzM0FUJj9L8goj3wCDG5kPI8mD7/KhmPYP1HsVvNDsnRe8hdA5EIv0jPXk8gZurOSfGZmQaLC5WJC8UCfVUoRfwRS4u+lc7zozPT4pMm7CSrAnGIMaqyIqdIaCJ5PGF2MZd9ax+h02Ih3sdsDbm/TckPk7t1JeUlWCWSjJc/cb5YUuBPSzYAU8ux/kEOL7a1QUITFJ5VnXUN0FF0sKoa+avj8kqHp5/IXHhv/eF9Vtum6eqtSO2zn3GFwhCXrPNr+TRxRd+QeL+n9nd5A+rYEK9kp2LnsvyFYGt6zq6mGHVV5aQEZOX+DTNL1A8aLI9RiKtgml1mc7tS424ni1yFPo39XF0r1JlPNaSEZuXEpWhUil7fOjXsC0JjliO6tSf2782Li2hkMejxM4OrnVc3eswO6zIvKREZ+WlFchyi1SgCmxUq+84k8tEEmpI9etsYpv37GG+NE+hVKgoih7Krv9uqooVMDUfzKM0pTkr7AVQvXy5ut6hwRvqu6TCXr6Ah6kFlabMJ/5UXNyFjdq4vtaH1CWxDmaoJ1ycD9GP8rLTi2QyJWjrl6trrmpLq1IllVpLj6nLZvJ5KkXFYaHlhainmGvZIar0hiVlOEurvZYUey13CY/PF4t5rrUdGrQifaj1IesaEiyN7XigBK5ANEewNERzBEtDNEewNERzBEtDNEewNP8fAAD//7JdWNYAAAAGSURBVAMAn+tNoGX3N30AAAAASUVORK5CYII=",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x130962e50>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2819aac",
      "metadata": {},
      "source": [
        "# Print all messages in the result\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_print())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "095ccbf1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RecommendationResponse(user_id=123, recommendations=['Back to the Future', \"Pee-wee's Big Adventure\", 'Forrest Gump', 'The Shawshank Redemption', 'The Silence of the Lambs', 'The Usual Suspects', 'The Sixth Sense', 'Apollo 13', \"Jacob's Ladder\", 'GoodFellas'])"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['structured_response']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "1cee4055",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on your watchlist, your key preferences seem to include:\\n\\n1. **Diverse Genres with a Focus on Drama and Thriller:** You enjoy intense narratives, from psychological thrillers (The Silence of the Lambs, The Sixth Sense) to crime and noir (Fargo, Reservoir Dogs, L.A. Confidential).\\n\\n2. **Strong Character Development and Emotional Depth:** Films like Forrest Gump, Schindler’s List, The Green Mile, and Saving Private Ryan showcase a preference for emotionally compelling stories with memorable characters.\\n\\n3. **Clever, Thought-Provoking, and Stylish Films:** You appreciate movies with unique storytelling, like Being John Malkovich, Pulp Fiction, Run Lola Run, and The Matrix.\\n\\n4. **Humor and Quirky Elements:** You include comedies and offbeat films such as Pee-wee’s Big Adventure, Grosse Pointe Blank, Friday, and Clerks, indicating an appreciation for humor and eccentricity.\\n\\n5. **Awards and Critical Acclaim:** Many of your picks are critically acclaimed or award-winning, reflecting a taste for well-crafted, impactful cinema.\\n\\n6. **Variety of Settings and Time Periods:** Your choices span historical (Schindler’s List, Braveheart) and imaginative worlds (Aladdin, The Lion King, Toy Story).\\n\\n**In summary:** You prefer films that combine emotional depth, clever storytelling, strong characters, and stylistic flair across various genres—especially dramas, thrillers, and critically acclaimed films with unique narratives.'"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['preferences']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1413e7c8",
      "metadata": {},
      "source": [
        "# Discussed on last meeting\n",
        "\n",
        "Goal: given a set of users, produce a set of k fair recommendations for each user.\n",
        "\n",
        "Variant: individual fairness\n",
        "\n",
        "Variant 1: no fairness + individual\n",
        "\n",
        "variant2: memory+holistic fairness\n",
        "\n",
        "-----\n",
        "\n",
        "Variant2: holistic and no memory\n",
        "\n",
        "Verify if an LLM is able to enforce fairness\n",
        "\n",
        "Verify an LLM is able to enforce fairness holistically or individually\n",
        "\n",
        "Impact of memory on the LLM’s ability to enforce fairness\n",
        "\n",
        "\n",
        "-> Implementar o componente de memória\n",
        "-> Pensar em como estruturar os prompts para cada variante com base na memória\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "73528439",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RecommendationResponse(user_id=123, recommendations=['Back to the Future', \"Pee-wee's Big Adventure\", 'Forrest Gump', 'The Shawshank Redemption', 'The Silence of the Lambs', 'The Usual Suspects', 'The Sixth Sense', 'Apollo 13', \"Jacob's Ladder\", 'GoodFellas'])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resp : RecommendationResponse = result['structured_response']\n",
        "resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "de73a701",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_id</th>\n",
              "      <th>Item_id</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Gender</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [User_id, Item_id, Rating, Timestamp, Gender, datetime]\n",
              "Index: []"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_target_user_id = get_raw_user_ids(ratings_pp, [resp.user_id])[0]\n",
        "test_ratings[test_ratings.User_id == raw_target_user_id]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.11.14)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
