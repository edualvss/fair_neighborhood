{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Multi-Agentic Recommendation System Pipeline\n",
        "This notebook demonstrates a modular, multi-agentic pipeline for evaluating recommender systems with context engineering.\n",
        "\n",
        "Each agent is responsible for a specific function, and context engineering is used to enhance the recommendation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61a5da1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Go to root dir to load the code from `src` and dataset from the specific folder\n",
        "import os\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eas/Documents/GitHub/fair_neighborhood/venv/lib/python3.11/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from scipy.sparse import lil_matrix\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
        "from recpack.preprocessing.filters import Deduplicate, MinRating, MinItemsPerUser\n",
        "from recpack.scenarios import WeakGeneralization, StrongGeneralization\n",
        "\n",
        "from hyperopt import fmin, tpe, hp\n",
        "\n",
        "# helpers & metrics\n",
        "from src.helper_functions.data_formatting import *\n",
        "from src.helper_functions.metrics_accuracy import *\n",
        "from src.helper_functions.metrics_coverage import *\n",
        "from src.helper_functions.metrics_exposure import *\n",
        "\n",
        "# models\n",
        "from src.recommenders.ease import myEASE\n",
        "from src.recommenders.slim_bn import BNSLIM\n",
        "from src.recommenders.fslr import FSLR\n",
        "from src.recommenders.slim_bn_admm import BNSLIM_ADMM\n",
        "from src.recommenders.mf_fair import FairMF\n",
        "from src.recommenders.fda import FDA_bpr\n",
        "\n",
        "import json\n",
        "import re\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "# import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b9a6e713",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(filename=\"recsys.log\", level=logging.WARN, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2365d484",
      "metadata": {},
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "31bd30ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/p_/s2y5jw396vjd9c8fql74n7600000gn/T/ipykernel_52882/2820513550.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  users[\"Gender\"] = users[\"Gender\"].replace({\"M\": 0, \"F\": 1})\n"
          ]
        }
      ],
      "source": [
        "# load ratings.dat from ml-1m folder\n",
        "ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, usecols=[0,1,2,3], names=[\"User_id\",\"Item_id\",\"Rating\",\"Timestamp\"], engine=\"python\")\n",
        "\n",
        "# load movies.dat from ml-1m folder\n",
        "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, usecols=[0,1,2], names=[\"Item_id\", \"Title\", \"Genre\"], encoding=\"latin-1\", engine=\"python\")\n",
        "movies[\"Genre\"] = movies[\"Genre\"].apply(lambda x: x.split(\"|\"))\n",
        "movies_items = movies\n",
        "movies = movies.explode(\"Genre\")\n",
        "\n",
        "# load users.dat from ml-1m folder\n",
        "users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", header=None, usecols=[0,1], names=[\"User_id\", \"Gender\"], encoding=\"latin-1\", engine=\"python\")\n",
        "\n",
        "# replace \"M\" with 0 and \"F\" with 1 in the \"Gender\" column\n",
        "users[\"Gender\"] = users[\"Gender\"].replace({\"M\": 0, \"F\": 1})\n",
        "\n",
        "# join ratings on users with User_id\n",
        "ratings = pd.merge(ratings, users, on=\"User_id\", how=\"left\")\n",
        "ratings['datetime'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
        "ratings = ratings.sort_values('datetime').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e812a5",
      "metadata": {},
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f2cd257",
      "metadata": {},
      "source": [
        "#### Temporal Splitting\n",
        "\n",
        "Split the dataset into train and test sets based on a timestamp for temporal evaluation.\n",
        "\n",
        "* 50% oldest interactions for train (base set)\n",
        "* 50% newest interactions for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "24071c3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 500105\n",
            "Test set size: 500104\n",
            "Split timestamp: 973018006.0\n",
            "Split datetime: 2000-10-31 18:46:46\n"
          ]
        }
      ],
      "source": [
        "# Split ratings into train and test sets based on timestamp (temporal split)\n",
        "# Example: Use the 80th percentile of timestamps as the split point\n",
        "#split_point = ratings[\"Timestamp\"].quantile(0.8)\n",
        "split_point = ratings[\"Timestamp\"].quantile(0.5) # 50% temporal split\n",
        "train_ratings = ratings[ratings[\"Timestamp\"] <= split_point]\n",
        "test_ratings = ratings[ratings[\"Timestamp\"] > split_point]\n",
        "\n",
        "print(f\"Train set size: {len(train_ratings)}\")\n",
        "print(f\"Test set size: {len(test_ratings)}\")\n",
        "print(f\"Split timestamp: {split_point}\")\n",
        "print(f\"Split datetime: {pd.to_datetime(split_point, unit='s')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "46a1e152",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train - Users: 3255 | Items: 3551 \n",
            "Test - Users: 3415 | Items: 3643 \n"
          ]
        }
      ],
      "source": [
        "print(\"Train - Users: {} | Items: {} \".format(train_ratings.User_id.unique().shape[0],train_ratings.Item_id.unique().shape[0]))\n",
        "print(\"Test - Users: {} | Items: {} \".format(test_ratings.User_id.unique().shape[0],test_ratings.Item_id.unique().shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dfff6a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7088c7fd44d343a5a3f16ccdd9295a81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/290311 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d2519c2f17d47dea39530996a2f8295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/290311 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ratings_pp = DataFramePreprocessor(\"Item_id\", \"User_id\",\"Timestamp\")\n",
        "\n",
        "# define filters\n",
        "deduplicate = Deduplicate(\"Item_id\", \"User_id\", \"Timestamp\")\n",
        "min_rating_filter = MinRating(4, \"Rating\")\n",
        "min_items_per_user_filter = MinItemsPerUser(10, \"Item_id\", \"User_id\") # Don't filter users with less than 10 interactions --- IGNORE ---\n",
        "\n",
        "# add filters to pre-processor\n",
        "ratings_pp.add_filter(deduplicate)\n",
        "ratings_pp.add_filter(min_rating_filter)\n",
        "ratings_pp.add_filter(min_items_per_user_filter)\n",
        "\n",
        "# create interaction matrix object\n",
        "# im = ratings_pp.process(ratings)\n",
        "im_train = ratings_pp.process(train_ratings)\n",
        "# im_test = ratings_pp.process(test_ratings)\n",
        "#im, im_train, im_test = ratings_pp.process_many(ratings, train_ratings, test_ratings)\n",
        "\n",
        "# apply filters to ratings frame directly\n",
        "#ratings = min_items_per_user_filter.apply(min_rating_filter.apply(deduplicate.apply(ratings)))\n",
        "#train_ratings = min_items_per_user_filter.apply(min_rating_filter.apply(deduplicate.apply(train_ratings)))\n",
        "ratings = min_rating_filter.apply(deduplicate.apply(ratings))\n",
        "train_ratings = min_rating_filter.apply(deduplicate.apply(train_ratings))\n",
        "\n",
        "movies = movies[movies[\"Item_id\"].isin(ratings[\"Item_id\"].unique())] # only keep items that are in the filtered ratings\n",
        "raw_genre_dict = dict(movies.groupby(\"Genre\")[\"Item_id\"].apply(lambda x: list(set(x))))\n",
        "\n",
        "# genre - inner iids dictionary\n",
        "inner_genre_dict = {\n",
        "    genre: get_inner_item_ids(ratings_pp, raw_iids) for genre, raw_iids in raw_genre_dict.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5064073e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### UPDATE\n",
        "# Remove year from movie titles for better readability\n",
        "YEAR_MOVIE_TITLES_PATTERN = r'\\s*\\(\\d{4}\\)'\n",
        "original_movie_titles = movies.Title.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "75965873",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### UPDATE\n",
        "# Create a mapping from original titles to updated titles without year\n",
        "original_to_updated_titles = {title : re.sub(YEAR_MOVIE_TITLES_PATTERN,'',title) for title in original_movie_titles}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "742d95fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### UPDATE\n",
        "# Fix titles that have \", The\" or \", A\" at the end\n",
        "for title in original_to_updated_titles:\n",
        "    if \",\" in original_to_updated_titles[title]:\n",
        "        parts = original_to_updated_titles[title].split(\",\")\n",
        "        if len(parts) == 2:\n",
        "            if parts[1] == ' The':\n",
        "                original_to_updated_titles[title] = 'The ' + parts[0]\n",
        "            elif parts[1] == ' A':\n",
        "                original_to_updated_titles[title] = 'A ' + parts[0]\n",
        "        \n",
        "updated_to_original_titles = {original_to_updated_titles[original_title] : original_title for original_title in original_to_updated_titles}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "917b1a4e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>3349</th>\n",
              "      <th>3350</th>\n",
              "      <th>3351</th>\n",
              "      <th>3352</th>\n",
              "      <th>3353</th>\n",
              "      <th>3354</th>\n",
              "      <th>3355</th>\n",
              "      <th>3356</th>\n",
              "      <th>3357</th>\n",
              "      <th>3358</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3359 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     6     7     8     9     ...  3349  \\\n",
              "0     1     1     1     1     1     1     1     1     1     1  ...     0   \n",
              "1     1     0     0     0     1     0     0     0     0     1  ...     0   \n",
              "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "3     1     0     1     0     0     0     0     0     1     1  ...     0   \n",
              "4     0     1     1     1     1     0     1     0     1     0  ...     0   \n",
              "\n",
              "   3350  3351  3352  3353  3354  3355  3356  3357  3358  \n",
              "0     0     0     0     0     0     0     0     0     0  \n",
              "1     0     0     0     0     0     0     0     0     0  \n",
              "2     0     0     0     0     0     0     0     0     0  \n",
              "3     0     0     0     0     0     0     0     0     0  \n",
              "4     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[5 rows x 3359 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### UPDATE\n",
        "pd.DataFrame.sparse.from_spmatrix(im_train.binary_values).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7c465c4c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([6037]), array([3]))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_raw_user_ids(ratings_pp,[3]), get_inner_user_ids(ratings_pp,[6037])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f45cb31f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base data - U[3153] | I[3359]\n"
          ]
        }
      ],
      "source": [
        "#print(f\"Full data - U[{len(im.active_users)}] | I[{len(im.active_items)}]\")\n",
        "print(f\"Base data - U[{len(im_train.active_users)}] | I[{len(im_train.active_items)}]\")\n",
        "#print(f\"Test data - U[{len(im_test.active_users)}] | I[{len(im_test.active_items)}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af974c2",
      "metadata": {},
      "source": [
        "## Data Statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e4f278",
      "metadata": {},
      "source": [
        "### Full dataset"
      ]
    },
    {
      "cell_type": "raw",
      "id": "7a327ad7",
      "metadata": {},
      "source": [
        "# compute sparsity after filtering\n",
        "sparsity = 1 - im.density\n",
        "\n",
        "# calculate user interaction and item popularity ranges\n",
        "user_interactions = im.binary_values.sum(axis=1)\n",
        "item_popularities = im.binary_values.sum(axis=0)\n",
        "print(f\"User interaction ranges from {user_interactions.min()} to {user_interactions.max()}. Item popularity ranges from {item_popularities.min()} to {item_popularities.max()}.\")\n",
        "\n",
        "# get the raw ids of all users involved\n",
        "raw_uids = get_raw_user_ids(ratings_pp, im.active_users)\n",
        "\n",
        "# create uid - gender mapping df\n",
        "gender_mapping_df = ratings[ratings[\"User_id\"].isin(raw_uids)][[\"User_id\", \"Gender\"]].drop_duplicates()\n",
        "\n",
        "# get the raw/inner ids of all females involved\n",
        "raw_uids_f = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 1, \"User_id\"].to_numpy()\n",
        "inner_uids_f = get_inner_user_ids(ratings_pp, raw_uids_f)\n",
        "\n",
        "# get the raw/inner ids of all males involved\n",
        "raw_uids_m = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 0, \"User_id\"].to_numpy()\n",
        "inner_uids_m = get_inner_user_ids(ratings_pp, raw_uids_m)\n",
        "\n",
        "num_interactions_f, num_interactions_m = im.binary_values[inner_uids_f].sum(), im.binary_values[inner_uids_m].sum()\n",
        "\n",
        "# table stats\n",
        "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
        "statTable1.add_row([\"ML1M\", str(im.num_active_users), str(im.num_active_items), str(im.num_interactions), str(round(sparsity*100,2))])\n",
        "print(statTable1)\n",
        "\n",
        "statTable2 = PrettyTable([\"data set\",\"attribute\",\"|F|\",\"int(F)\",\"|M|\",\"int(M)\"])\n",
        "statTable2.add_row([\"ML1M\", \"gender\", str(len(raw_uids_f)), str(num_interactions_f), str(len(raw_uids_m)), str(num_interactions_m)])\n",
        "print(statTable2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e408d0c8",
      "metadata": {},
      "source": [
        "### Base dataset (50% oldest interactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c7286e47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User interaction ranges from 10 to 1063. Item popularity ranges from 1 to 1413.\n",
            "+----------+------+------+--------+----------+\n",
            "| data set | |U|  | |I|  | int(I) | sparsity |\n",
            "+----------+------+------+--------+----------+\n",
            "|   ML1M   | 3153 | 3359 | 290311 |  97.26   |\n",
            "+----------+------+------+--------+----------+\n",
            "+----------+-----------+-----+--------+------+--------+\n",
            "| data set | attribute | |F| | int(F) | |M|  | int(M) |\n",
            "+----------+-----------+-----+--------+------+--------+\n",
            "|   ML1M   |   gender  | 907 | 75923  | 2246 | 214388 |\n",
            "+----------+-----------+-----+--------+------+--------+\n"
          ]
        }
      ],
      "source": [
        "# compute sparsity after filtering\n",
        "sparsity = 1 - im_train.density\n",
        "\n",
        "# calculate user interaction and item popularity ranges\n",
        "user_interactions = im_train.binary_values.sum(axis=1)\n",
        "item_popularities = im_train.binary_values.sum(axis=0)\n",
        "print(f\"User interaction ranges from {user_interactions.min()} to {user_interactions.max()}. Item popularity ranges from {item_popularities.min()} to {item_popularities.max()}.\")\n",
        "\n",
        "# get the raw ids of all users involved\n",
        "raw_uids = get_raw_user_ids(ratings_pp, im_train.active_users)\n",
        "\n",
        "# create uid - gender mapping df\n",
        "gender_mapping_df = train_ratings[train_ratings[\"User_id\"].isin(raw_uids)][[\"User_id\", \"Gender\"]].drop_duplicates()\n",
        "\n",
        "# get the raw/inner ids of all females involved\n",
        "raw_uids_f = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 1, \"User_id\"].to_numpy()\n",
        "inner_uids_f = get_inner_user_ids(ratings_pp, raw_uids_f)\n",
        "\n",
        "# get the raw/inner ids of all males involved\n",
        "raw_uids_m = gender_mapping_df.loc[gender_mapping_df[\"Gender\"] == 0, \"User_id\"].to_numpy()\n",
        "inner_uids_m = get_inner_user_ids(ratings_pp, raw_uids_m)\n",
        "\n",
        "num_interactions_f, num_interactions_m = im_train.binary_values[inner_uids_f].sum(), im_train.binary_values[inner_uids_m].sum()\n",
        "\n",
        "# table stats\n",
        "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
        "statTable1.add_row([\"ML1M\", str(im_train.num_active_users), str(im_train.num_active_items), str(im_train.num_interactions), str(round(sparsity*100,2))])\n",
        "print(statTable1)\n",
        "\n",
        "statTable2 = PrettyTable([\"data set\",\"attribute\",\"|F|\",\"int(F)\",\"|M|\",\"int(M)\"])\n",
        "statTable2.add_row([\"ML1M\", \"gender\", str(len(raw_uids_f)), str(num_interactions_f), str(len(raw_uids_m)), str(num_interactions_m)])\n",
        "print(statTable2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75dfbf06",
      "metadata": {},
      "source": [
        "### Train and test backbones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9ecf070d",
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 1994"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a3538b16",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b04e66f362db463fb0c0da4e1167180a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c6ca024477f42799304b76442c954a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model ease...\n",
            "2025-11-23 16:33:32,768 - base - recpack - INFO - Fitting myEASE complete - Took 1.35s\n",
            "Fit time: {'ease': 1.360753059387207}\n",
            "Model: ease | NDCG@10: 0.3066 (±0.2309) | Recall@10: 0.2915 (±0.2135)\n",
            "Model: ease | NDCG@20: 0.3051 (±0.1935) | Recall@20: 0.3192 (±0.1952)\n"
          ]
        }
      ],
      "source": [
        "class TrainedBackbones:\n",
        "    \n",
        "    def __init__(self,interaction_matrix):\n",
        "        self.im = interaction_matrix\n",
        "        \n",
        "        # Create scenario for train and test the backbone        \n",
        "        self.scenario = WeakGeneralization(validation=True, seed=SEED)\n",
        "        self.scenario.split(self.im)\n",
        "\n",
        "        # Load optimized parameters\n",
        "        with open(f\"ml-1m/{SEED}/opt_params.json\", \"r\") as f: opt_params = json.load(f)\n",
        "        # Initialize models\n",
        "        self.models = self.initialize_models(opt_params)\n",
        "        # Prepare to output\n",
        "        self.predictions = dict()\n",
        "        self.fit_time = dict()\n",
        "        self.iters_num = dict()\n",
        "\n",
        "        # Build the backbone models and generate the outputs\n",
        "        self.train_test_models()\n",
        "        \n",
        "    def initialize_models(self,opt_params):\n",
        "        return {\n",
        "            \"ease\": myEASE(l2=opt_params[\"ease\"][\"l2\"], method=\"user\"),\n",
        "        #   \"bnslim\": BNSLIM(knn=100, l1=opt_params[\"bnslim\"][\"l1\"], l2=opt_params[\"bnslim\"][\"l2\"], l3=opt_params[\"bnslim\"][\"l3\"], maxIter=50, method=\"user\", seed=SEED),\n",
        "        #    \"fslr\": FSLR(l1=opt_params[\"fslr\"][\"l1\"], l2=opt_params[\"fslr\"][\"l2\"], method=\"user\"),\n",
        "        #    \"bnslim_admm\": BNSLIM_ADMM(l1=opt_params[\"bnslim_admm\"][\"l1\"], l2=opt_params[\"bnslim_admm\"][\"l2\"], l3=opt_params[\"bnslim_admm\"][\"l3\"], method=\"user\"),\n",
        "        #    \"fairmf\": FairMF(batch_size=im.num_active_users, l2=opt_params[\"fairmf\"][\"l2\"], learning_rate=opt_params[\"fairmf\"][\"learning_rate\"], num_factors=opt_params[\"fairmf\"][\"num_factors\"], seed=SEED),\n",
        "        #    \"fda\": FDA_bpr(noise_ratio=opt_params[\"fda\"][\"noise_ratio\"], num_ng=opt_params[\"fda\"][\"num_ng\"],seed=SEED)\n",
        "        }\n",
        "\n",
        "    def train_test_models(self):\n",
        "\n",
        "        #### PARAMETERS INIT\n",
        "        # parameters for fairmf\n",
        "        sst_field = torch.zeros((self.im.num_active_users, self.im.num_active_items), dtype=torch.bool)\n",
        "        sst_field[inner_uids_f, :] = True\n",
        "        # parameters for fda\n",
        "        users_features = np.zeros(self.im.num_active_users); users_features[inner_uids_m] = 1\n",
        "\n",
        "        for model_name, model in self.models.items():\n",
        "            print(f\"Training model {model_name}...\")\n",
        "\n",
        "            params = {}\n",
        "            if model_name == \"fslr\":\n",
        "                params = {\"inner_ids_pr\": inner_uids_f, \"inner_ids_npr\": inner_uids_m}\n",
        "            elif model_name in [\"bnslim\", \"bnslim_admm\"]:\n",
        "                params = {\"inner_ids_npr\": inner_uids_m}\n",
        "            elif model_name == \"fairmf\":\n",
        "                params = {\"sst_field\": sst_field}\n",
        "            elif model_name == \"fda\":\n",
        "                params = {\"users_features\": users_features}\n",
        "            \n",
        "            start_time = time.time()\n",
        "            model.fit(self.scenario.full_training_data.binary_values, **params)\n",
        "            self.fit_time[model_name] = time.time() - start_time\n",
        "            print(f\"Fit time: {self.fit_time}\")\n",
        "\n",
        "            if model_name == \"fairmf\":\n",
        "                self.iters_num[model_name] = model.epochs\n",
        "            else:\n",
        "                self.iters_num[model_name] = model.iters\n",
        "\n",
        "            # generate predictions and mask training interactions\n",
        "            y_pred = None\n",
        "            if model_name == \"fda\":\n",
        "                y_pred = model.model_.predict()\n",
        "            else:\n",
        "                y_pred = model.predict(self.scenario.full_training_data.binary_values)\n",
        "            self.predictions[model_name] = y_pred.toarray()\n",
        "            # mask\n",
        "            self.predictions[model_name][self.scenario.full_training_data.binary_values.nonzero()] = -np.inf\n",
        "\n",
        "            for K in [10,20]:\n",
        "                ndcg, std_ndcg = tndcg_at_n(self.predictions[model_name], self.scenario.test_data_out.binary_values, K)\n",
        "                recall, std_recall = recall_at_n(self.predictions[model_name], self.scenario.test_data_out.binary_values, K)\n",
        "\n",
        "                print(f\"Model: {model_name} | NDCG@{K}: {ndcg:.4f} (±{std_ndcg:.4f}) | Recall@{K}: {recall:.4f} (±{std_recall:.4f})\"  )\n",
        "\n",
        "\n",
        "    def get_items_ranking(self, items_ids):\n",
        "        raw_items_ids = get_raw_item_ids(ratings_pp,items_ids)      # RAW: from dataset\n",
        "        #inner_items_ids = get_inner_item_ids(ratings_pp,items_ids) # INNER: used by recpack\n",
        "        rec_items = []\n",
        "        for i, item_id in enumerate(raw_items_ids):\n",
        "            item_original_title = movies_items[movies_items.Item_id == item_id].Title.values[0]\n",
        "            rec_item = {\n",
        "                \"item_id\": int(item_id),\n",
        "                \"item_title\": original_to_updated_titles[item_original_title],\n",
        "                \"position\": i+1\n",
        "            }\n",
        "            rec_items.append(rec_item)\n",
        "\n",
        "        return rec_items\n",
        "\n",
        "    def get_candidate_items(self, user_id, model_name, top_k):\n",
        "        user_top_items = get_topn_indices(self.predictions[model_name],top_k)[user_id]\n",
        "        return self.get_items_ranking(user_top_items)\n",
        "\n",
        "    def get_models_name(self):\n",
        "        return self.models.keys()\n",
        "\n",
        "    def get_raw_item_ids_from_titles_in_catalog(self, item_titles : list[str]):\n",
        "        catalog = movies.drop_duplicates(subset=['Item_id','Title'])\n",
        "        return catalog[catalog.Title.isin(item_titles)]['Item_id'].tolist()\n",
        "\n",
        "\n",
        "#backbones = TrainedBackbones(im)\n",
        "backbones = TrainedBackbones(im_train)\n",
        "\n",
        "# define the models, list sizes, and metrics\n",
        "#list_sizes = [10, 20, 50, 100]\n",
        "list_sizes = [10,20]\n",
        "metrics = [\"recall\",'recall_reranking',\"ndcg\", \"ndcg_reranking\", ## UPDATE\n",
        "           \"c-equity\",\"c-equity_reranking\", \"u-parity\",\"u-parity_reranking\"] ## UPDATE\n",
        "\n",
        "# initialize a dictionary to store results with mean and standard deviation\n",
        "results = {\n",
        "    \"iters_num\": {model: 0 for model in [\"bnslim\", \"fslr\", \"bnslim_admm\", \"fairmf\"]},\n",
        "    \"fit_time\": {model: 0 for model in backbones.models.keys()},\n",
        "    \"reranking_sample_users\": {model: 0 for model in backbones.models.keys()}, ## UPDATE\n",
        "    **{metric: {model: {size: {\"mean\": 0, \"std\": 0} for size in list_sizes} for model in backbones.models.keys()} for metric in metrics},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e147392",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# Context Engineering Elements Recommender System\n",
        "Define modular functions/classes for each context element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e99ef139",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt-4.1-nano\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "215b63a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
        "os.environ['LANGSMITH_PROJECT'] = \"ml-agentic-recommender\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "915f6957",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_im = im_train # The interaction matrix to use in tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5ad85f",
      "metadata": {},
      "source": [
        "## CMem - Memory Structure\n",
        "\n",
        "> Memory ID: An experiment number (experiment_id). Can be a fixed value. Same value for user and system space.\n",
        "\n",
        "### User space (namespace for memory)\n",
        "* Level 1: user_id\n",
        "* Level 2: the \"memories\" (e.g. user preferences, recommended items, ...)\n",
        "\n",
        "**User's memories:**\n",
        "* \"preferences\": avoid request preferences multiple times for the same user.\n",
        "* \"recommendations\": avoid repeat some already recommended item for the user.\n",
        "\n",
        "\n",
        "### System space (global state):\n",
        "* Level 1: \"system\"\n",
        "* Level 2: \"counter\" # Count how many request are done in the system\n",
        "\n",
        "### System space -- Metrics\n",
        "* Level 1: \"metrics\"\n",
        "* Leve 2: \n",
        "    * \"c-equity\": exposure metric for C-fairness\n",
        "    * \"u-parity\": coverage metric for C-fairness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f3628d5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_id = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf59a7f",
      "metadata": {},
      "source": [
        "## CTools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa1a330f",
      "metadata": {},
      "source": [
        "### Get User History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "02fb96f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool, ToolRuntime\n",
        "\n",
        "@tool(\"GetUserHistory\",description=\"Get the history of items of the user from the oldest to newest watched movie.\")\n",
        "def get_user_history(user_id:int) -> str:\n",
        "        \n",
        "    print(f\"[GetUserHistory] user_id: {user_id}\")\n",
        "    logger.info(f\"[GetUserHistory] user_id: {user_id}\")\n",
        "    inner_user_id, inner_item_ids = next(base_im.users_in([user_id]).binary_item_history)\n",
        "    \n",
        "    raw_user_id = get_raw_user_ids(ratings_pp,[inner_user_id])[0]\n",
        "    raw_item_ids = get_raw_item_ids(ratings_pp,inner_item_ids)\n",
        "\n",
        "    movies_id_title = movies.loc[movies.Item_id.isin(raw_item_ids),['Item_id','Title']].drop_duplicates()\n",
        "    movies_id_title.Title = movies_id_title.Title.apply(lambda x : original_to_updated_titles[x])\n",
        "    movies_id_title['User_id'] = raw_user_id\n",
        "\n",
        "    return ', '.join(pd.merge(movies_id_title,ratings,on=['User_id','Item_id']).sort_values('Timestamp').reset_index(drop=True)[['Title']].values.reshape(-1))\n",
        "\n",
        "#get_user_history({\"user_id\":0})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d41d5d4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"GetNotInteractedItemsByTheUser\",description=\"Get all items from the catalog which the user has not interacted with.\")\n",
        "def get_non_interacted_items(user_id:int) -> list[int]:\n",
        "    \n",
        "    logger.info(f\"[GetNotInteractedItemsByTheUser] user_id: {user_id}\")\n",
        "    inner_user_id, inner_item_ids = next(base_im.users_in([user_id]).binary_item_history)\n",
        "    all_inner_item_ids = set(base_im.active_items)\n",
        "    non_interacted_inner_item_ids = list(all_inner_item_ids - set(inner_item_ids))\n",
        "    raw_not_interacted_item_ids = get_raw_item_ids(ratings_pp,non_interacted_inner_item_ids)\n",
        "\n",
        "    return '; '.join(movies_items.loc[movies_items.Item_id.isin(raw_not_interacted_item_ids),'Title'].apply(lambda x : original_to_updated_titles[x]).values)\n",
        "\n",
        "#get_non_interacted_items(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c1d3d9",
      "metadata": {},
      "source": [
        "### Filter candidate set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "127a88c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool(\"FilterCandidateSet\",description=\"Get the filtered items from the backbone recommender model to compose the candidate set for recommendation.\")\n",
        "def get_user_candidate_set(user_id : int, top_k : int = 20, backbone_model_name : str =\"ease\") -> str:\n",
        "    \n",
        "    print(f\"[FilterCandidateSet] User[{user_id}], Model: {backbone_model_name}, Top K: {top_k}\")\n",
        "    logger.info(f\"[FilterCandidateSet] User[{user_id}] - Model: {backbone_model_name}, Top K: {top_k}\")\n",
        "\n",
        "    return ', '.join([ item['item_title'] for item in backbones.get_candidate_items(user_id, backbone_model_name,top_k) ])\n",
        "\n",
        "#get_user_candidate_set({\"user_id\":0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "62d9a2d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def collaborative_filtering(im,user_id,num_sim_users, num_items):\n",
        "    # TODO: Fazer filtragem colaborativa comum\n",
        "    similarity_matrix = im.binary_values @ im.binary_values.T\n",
        "    sim_mat = similarity_matrix.toarray()\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "960de577",
      "metadata": {},
      "source": [
        "### Generate User Preferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "81fcfc62",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.messages import HumanMessage, SystemMessage, ToolMessage\n",
        "from langgraph.types import Command\n",
        "from langchain.agents import AgentState\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from typing import List\n",
        "\n",
        "class UserContext(BaseModel):\n",
        "    user_id: int\n",
        "    session_id : int\n",
        "\n",
        "class RecommenderAgentState(AgentState):  \n",
        "    preferences: str\n",
        "    recommended_items: List[str]\n",
        "\n",
        "@tool(\"GetUserPreferences\",description=\"Infer the user preferences based on the user history of watched movies.\")\n",
        "def get_user_preferences(user_history:str, runtime:ToolRuntime[UserContext,RecommenderAgentState]) -> str:\n",
        "\n",
        "    # # Context\n",
        "    # if runtime.context:\n",
        "    #     print(f\"[GetUserPreferences - context] Context: {runtime.context}\")\n",
        "\n",
        "    print(f\"[GetUserPreferences] User[{runtime.context.user_id}] history length: {len(user_history)}\")\n",
        "    logger.info(f\"[GetUserPreferences] User[{runtime.context.user_id}] history length: {len(user_history)}\")\n",
        "    if(len(user_history.strip())==0):\n",
        "        logger.warning(f\"[GetUserPreferences] No User[{runtime.context.user_id}] history available.\")\n",
        "        return \"No user history available. Preferences cannot be inferred.\"\n",
        "    \n",
        "    # Memory\n",
        "    namespace_for_memory = (str(runtime.context.user_id),\"preferences\")\n",
        "    if runtime.store:\n",
        "        user_memory = runtime.store.get(namespace_for_memory,experiment_id)\n",
        "        if user_memory is not None:\n",
        "            user_prefs = user_memory.value['infered_preferences'] or None\n",
        "            if user_prefs is not None: # Using already generated preferences\n",
        "                logger.info(f\"[GetUserPreferences - Memory] User[{runtime.context.user_id}] Using existent preferences found in memory.\")\n",
        "                return Command(update={\n",
        "                    \"preferences\": user_prefs,\n",
        "                    \"messages\":[\n",
        "                        ToolMessage(\n",
        "                            user_prefs,\n",
        "                            tool_call_id=runtime.tool_call_id\n",
        "                        )\n",
        "                    ]\n",
        "                })\n",
        "\n",
        "    # New inference of preferences\n",
        "    system_msg = SystemMessage(\"You are a movie recommender specialist, tell me what are my preferences and explain them.\")\n",
        "    preferences_msg = HumanMessage(f\"The movies I have watched (watched movies): {user_history}.\\n\\nWhat features are most important to me when selecting movies (Summarize my preferences briefly)?\")\n",
        "\n",
        "    messages = [\n",
        "        system_msg,preferences_msg\n",
        "    ]\n",
        "\n",
        "    model = init_chat_model(MODEL_NAME)\n",
        "\n",
        "    response = model.invoke(messages)  # Returns AIMessage\n",
        "    \n",
        "    # Storing inferred preferences in the Memory\n",
        "    preference_memory = {\"infered_preferences\":response.content}\n",
        "    runtime.store.put(namespace_for_memory, experiment_id, preference_memory,index=False)\n",
        "    logger.info(f\"[GetUserPreferences - Memory] User[{runtime.context.user_id}] inferred preferences stored in memory.\")\n",
        "    # Tool response\n",
        "    return Command(update={\n",
        "        \"preferences\": response.content,\n",
        "        \"messages\":[\n",
        "            ToolMessage(\n",
        "                response.content,\n",
        "                tool_call_id=runtime.tool_call_id\n",
        "            )\n",
        "        ]\n",
        "    })\n",
        "\n",
        "#get_user_preferences(\"Moral Kombat, Fast and Furios\")\n",
        "# model = init_chat_model(MODEL_NAME)\n",
        "# model_with_tools = model.bind_tools([get_user_preferences])\n",
        "# response = model_with_tools.invoke(\"My watch history is Moral Kombat and Fast Furios. What are my preferences \")\n",
        "# print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942c9d80",
      "metadata": {},
      "source": [
        "### Check Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "id": "0fea4a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Expected output format\n",
        "class RecommendationResponse(BaseModel):\n",
        "    \"\"\"A list of recommended movies for the user.\"\"\"\n",
        "    user_id : int = Field(description=\"The user id of the generated recommendation list.\")\n",
        "    recommendations: List[str] = Field(description=\"A list of recommended movie titles\")\n",
        "\n",
        "\n",
        "@tool(\"CheckRecommendations\",description=\"Get a list of recommended movies and check if they are available in the catalog.\")\n",
        "def check_recommendations(result:RecommendationResponse, runtime: ToolRuntime[UserContext,RecommenderAgentState]) -> str:\n",
        "    \n",
        "    print(f\"[CheckRecommendations] User[{runtime.context.user_id}] - Recommendations length: {len(result.recommendations)}\")\n",
        "    \n",
        "    # Normalization of titles\n",
        "    recommended_titles = [title.strip() for title in result.recommendations] # Response normalization\n",
        "    available_in_original_title_lower = [title.lower() for title in original_to_updated_titles] # Normalize titles from the original catalog\n",
        "    available_in_updated_title_lower = [title.lower() for title in updated_to_original_titles] # Normalize titles from the updated catalog (cleaned titles)\n",
        "\n",
        "    final_recommendations = []\n",
        "\n",
        "    # Check if recommended titles are in the catalog\n",
        "    for title in recommended_titles:\n",
        "        lower_generated_title = title.lower()\n",
        "        if lower_generated_title in available_in_original_title_lower:\n",
        "            final_recommendations.append( original_to_updated_titles[[t for t in original_to_updated_titles if t.lower() == lower_generated_title][0]] )\n",
        "            continue\n",
        "        elif lower_generated_title in available_in_updated_title_lower:\n",
        "            final_recommendations.append( updated_to_original_titles[[t for t in updated_to_original_titles if t.lower() == lower_generated_title][0]] )\n",
        "            continue\n",
        "        else:\n",
        "            # If the title is not found in either catalog, stop and ask for new recommendations\n",
        "            logger.warning(f\"[CheckRecommendations] Recommended movie `{title}` not found in catalog for the user[{runtime.context.user_id}].\")\n",
        "            return f\"The recommended movie `{title}` are not available in the catalog. Please recommend another movie.\"\n",
        "\n",
        "    \n",
        "    # Update memory with new recommended items\n",
        "    namespace_for_memory = (str(runtime.context.user_id),\"recommendations\")\n",
        "    if runtime.store:\n",
        "        user_memory = runtime.store.get(namespace_for_memory,experiment_id)\n",
        "        if user_memory is not None:\n",
        "            user_previous_recs = user_memory.value.get('recommended_items',[])\n",
        "            logger.info(f\"[CheckRecommendations] User[{runtime.context.user_id}] already has recommendations: {user_previous_recs}\")\n",
        "            \n",
        "            for title in final_recommendations:\n",
        "                if title not in user_previous_recs:\n",
        "                    user_previous_recs.append(title)\n",
        "                else:\n",
        "                    logger.warning(f\"[CheckRecommendations] Title {title} already in recommended_items for user[{runtime.context.user_id}].\")\n",
        "            \n",
        "            runtime.store.put(namespace_for_memory, experiment_id, {\"recommended_items\": user_previous_recs}, index=False)\n",
        "        else:\n",
        "            # First time recommendations for the user, storing them in the memory\n",
        "            logger.info(f\"[CheckRecommendations] Storing first recommendations for User[{runtime.context.user_id}]: {final_recommendations}\")\n",
        "            runtime.store.put(namespace_for_memory, experiment_id, {\"recommended_items\": final_recommendations}, index=False)\n",
        "    else:\n",
        "        logger.warning(f\"[CheckRecommendations] There is no memory in the recommendation for the user[{runtime.context.user_id}]\")\n",
        "     \n",
        "\n",
        "    # Return the final recommendations\n",
        "    return Command(update={\n",
        "        \"recommended_items\": final_recommendations,\n",
        "        \"messages\":[\n",
        "            ToolMessage(\n",
        "                f\"All recommended movies are available in the catalog. They are added to the memory.\",\n",
        "                tool_call_id=runtime.tool_call_id\n",
        "            )\n",
        "        ]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2ecc3d",
      "metadata": {},
      "source": [
        "## CState"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9722f14",
      "metadata": {},
      "source": [
        "#### Original metrics calculation (from Fair Neighborhood backbone models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "id": "d99f7405",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_metrics(user_id,recommendation_list, K, model_name=\"ease\"):\n",
        "    print(f\" --- GetMetrics --- [{user_id}]@{K} (backbone_model={model_name})\")\n",
        "    # map recommended titles back to original titles in the dataset and get their inner ids in the backbone matrix\n",
        "    original_recommended_titles = [ updated_to_original_titles[recommended_movies] for recommended_movies in recommendation_list]\n",
        "    recommended_raw_item_ids = backbones.get_raw_item_ids_from_titles_in_catalog(original_recommended_titles)\n",
        "    recommended_inner_item_ids = get_inner_item_ids(ratings_pp,recommended_raw_item_ids)\n",
        "\n",
        "\n",
        "    # generated_predictions = backbones.predictions[model_name].copy() # With copy, does not change the original matrix\n",
        "    generated_predictions = backbones.predictions[model_name]\n",
        "    max_val = generated_predictions[user_id].max() # Get the greatest relevance score generated by the backbone for the user\n",
        "    # generated_predictions[resp.user_id,:] = -np.inf # Mask all items (need to check) \n",
        "    generated_predictions[user_id,recommended_inner_item_ids] = max_val + 0.5 # Force the reranked recommendations to have a greater score than backbone predictions\n",
        "\n",
        "    ## accuracy metrics (DON'T USE - there is no sense to perceive accuracy on the fly - \"we do not to know the future\")\n",
        "    # Backbone (if predictions are copied)\n",
        "    # back_mean_recall, back_std_recall = recall_at_n(backbones.predictions[model_name], backbones.scenario.test_data_out.binary_values, K)\n",
        "    # back_mean_ndcg, back_std_ndcg = tndcg_at_n(backbones.predictions[model_name], backbones.scenario.test_data_out.binary_values, K)\n",
        "    # print(f\"Backbone Model: {model_name} | NDCG@{K}: {back_mean_ndcg:.4f} (±{back_std_ndcg:.4f}) | Recall@{K}: {back_mean_recall:.4f} (±{back_std_recall:.4f})\" )\n",
        "    # Reranked \n",
        "    # mean_recall, std_recall = recall_at_n(generated_predictions, backbones.scenario.test_data_out.binary_values, K)\n",
        "    # mean_ndcg, std_ndcg = tndcg_at_n(generated_predictions, backbones.scenario.test_data_out.binary_values, K)\n",
        "    # print(f\"Reranking With: {model_name} | NDCG@{K}: {mean_ndcg:.4f} (±{std_ndcg:.4f}) | Recall@{K}: {mean_recall:.4f} (±{std_recall:.4f})\" )\n",
        "\n",
        "    ## fairness metrics\n",
        "    # Exposure\n",
        "    # Backbone (if predictions are copied)\n",
        "    # back_cequity_mean, back_cequity_std, _ = c_equity_at_n(backbones.predictions[model_name][inner_uids_f, :], backbones.predictions[model_name][inner_uids_m, :], inner_genre_dict, K)\n",
        "    # print(f\"Backbone Model: {model_name} | C-Equity@{K}: {back_cequity_mean:.4f} (±{back_cequity_std:.4f})\" )\n",
        "    # Reranked\n",
        "    cequity_mean, cequity_std, _ = c_equity_at_n(generated_predictions[inner_uids_f, :], generated_predictions[inner_uids_m, :], inner_genre_dict, K)\n",
        "    #print(f\"Reranking With: {model_name} | C-Equity@{K}: {cequity_mean:.4f} (±{cequity_std:.4f})\" )\n",
        "\n",
        "    # Coverage\n",
        "    females = np.ones(base_im.num_active_users); females[inner_uids_m] = 0\n",
        "    # Backbone (if predictions are copied)\n",
        "    # back_uparity_mean, back_uparity_std = u_parity_at_n(backbones.predictions[model_name],females, inner_genre_dict, K)\n",
        "    # print(f\"Backbone Model: {model_name} | U-Parity@{K}: {back_uparity_mean:.4f} (±{back_uparity_std:.4f})\" )\n",
        "    # Reranked\n",
        "    uparity_mean, uparity_std = u_parity_at_n(generated_predictions,females, inner_genre_dict, K)\n",
        "    #print(f\"Reranking With: {model_name} | U-Parity@{K}: {uparity_mean:.4f} (±{uparity_std:.4f})\" )\n",
        "    return {\n",
        "        \"c-equity-mean\": cequity_mean,\n",
        "        \"c-equity-std\": cequity_std,\n",
        "        \"u-parity-mean\": uparity_mean,\n",
        "        \"u-parity-std\": uparity_std\n",
        "    }\n",
        "\n",
        "#get_metrics(resp.user_id,resp.recommendations,10,\"ease\") # `resp` is generated after agent invoke"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5ac024",
      "metadata": {},
      "source": [
        "### Reranking Metrics (fairness metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c63780d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import after_agent\n",
        "from langgraph.runtime import Runtime\n",
        "from typing import Any\n",
        "\n",
        "# Runs after the agent completes its execution (a reranking/recommendation is made)\n",
        "@after_agent(state_schema=RecommenderAgentState)\n",
        "def calculate_metrics(state: RecommenderAgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
        "    result : RecommendationResponse = state['structured_response']\n",
        "\n",
        "    # c-fairness == consumer fairness (c-equity and u-parity)\n",
        "    c_fairness_metrics = get_metrics(result.user_id,result.recommendations,10,\"ease\")\n",
        "\n",
        "    recommender_counter = 1 # If memory fails, always overwrite with the last values at counter `1`\n",
        "    # Get/Update System \"STATE\"/MEMORY (metrics calculation)\n",
        "    if runtime.store:\n",
        "        ## Get/Update recommender counter\n",
        "        system_namespace = (\"system\",\"counter\")\n",
        "        system_memory = runtime.store.get(system_namespace,experiment_id)\n",
        "        if system_memory is not None:\n",
        "            recommender_counter = system_memory.value.get('recommender_counter',0)\n",
        "            recommender_counter += 1\n",
        "            \n",
        "        runtime.store.put(system_namespace, experiment_id, {\"recommender_counter\": recommender_counter}, index=False)\n",
        "        logger.info(f\"Generated Recommendation: {recommender_counter}\")\n",
        "    \n",
        "    ## Store the metric @ this point (recommender counter)\n",
        "    namespace_for_cequity = (\"metrics\",\"c-equity\")\n",
        "    namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "\n",
        "    #if recommender_counter % 5 == 0: # Calculate every 5 recommendations\n",
        "    print(f\"Metrics@{recommender_counter}: C-Equity: {c_fairness_metrics['c-equity-mean']:.4f} (±{c_fairness_metrics['c-equity-std']:.4f}), U-Parity: {c_fairness_metrics['u-parity-mean']:.4f} (±{c_fairness_metrics['u-parity-std']:.4f})\")\n",
        "    \n",
        "    runtime.store.put(namespace_for_cequity,recommender_counter,{\n",
        "                                                                 \"user_id\": result.user_id,\n",
        "                                                                 \"mean\": c_fairness_metrics['c-equity-mean'], \n",
        "                                                                 \"std\": c_fairness_metrics['c-equity-std']\n",
        "                                                                }, index=False)\n",
        "    runtime.store.put(namespace_for_uparity,recommender_counter,{\n",
        "                                                                 \"user_id\": result.user_id,\n",
        "                                                                 \"mean\": c_fairness_metrics['u-parity-mean'],\n",
        "                                                                 \"std\": c_fairness_metrics['u-parity-std']\n",
        "                                                                }, index=False)\n",
        "        \n",
        "    return None\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3246cc59",
      "metadata": {},
      "source": [
        "## CInst (System Instruction) - Agent Orchestration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "357b397d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.structured_output import ToolStrategy\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.store.memory import InMemoryStore \n",
        "from langchain.agents.middleware import ToolRetryMiddleware\n",
        "\n",
        "model = ChatOpenAI(model=MODEL_NAME)\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a movie recommender specialist.\n",
        "\n",
        "To recommend movies, you follow the steps:\n",
        "1. Get the user history of watched movies.\n",
        "2. Filter a candidate set of movies for the user.\n",
        "3. Based on the user history, always get the user preferences.\n",
        "4. Recommend 10 movies from the candidate set based on the users' preferences. The output should be a list of 10 movie titles only, without any additional text.\n",
        "5. Check if the recommended movies are available in the catalog. If any movie is not available, recommend another movie from the candidate set and replace the wrong one.\n",
        "6. If all recommended movies are available, output only the list of 10 movie titles and stop.\n",
        "\"\"\"\n",
        "\n",
        "tools = [get_user_history,get_user_candidate_set,get_user_preferences,check_recommendations]\n",
        "\n",
        "checkpointer = InMemorySaver() # Unused\n",
        "store = InMemoryStore() # In-memory store for context and state / memory - Instantiate once per experiment\n",
        "\n",
        "# Agent with all components of the recommender system in Context Engineering paradigm\n",
        "agent = create_agent(\n",
        "    model,\n",
        "    middleware=[calculate_metrics, ToolRetryMiddleware(\n",
        "            max_retries=3,\n",
        "            backoff_factor=2.0,\n",
        "            initial_delay=1.0,\n",
        "        )], # Cstate / Metrics\n",
        "    tools=tools, # Ctools\n",
        "    context_schema=UserContext, # Context control by user ID\n",
        "    system_prompt=system_prompt, # Cinst\n",
        "    response_format=ToolStrategy(RecommendationResponse), # Response\n",
        "    state_schema=RecommenderAgentState, # Last Recommendation\n",
        "    checkpointer=checkpointer, # Unused\n",
        "    store=store # Cmem / Cstate\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c68de2d",
      "metadata": {},
      "source": [
        "## CQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "id": "3818d7de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GetUserHistory] user_id: 0\n",
            "[GetUserPreferences] User[0] history length: 4037\n",
            "[CheckRecommendations] User[0] - Recommendations length: 10\n",
            "[CheckRecommendations] User[0] - Recommendations length: 10\n",
            "[CheckRecommendations] User[0] - Recommendations length: 10\n",
            " --- GetMetrics --- [0]@10 (backbone_model=ease)\n",
            "Metrics@4: C-Equity: 0.0410 (±0.0425), U-Parity: 0.07364545558772512 (±0.05442334470000494)\n",
            "[GetUserHistory] user_id: 1\n",
            "[GetUserPreferences] User[1] history length: 1712\n",
            "[CheckRecommendations] User[1] - Recommendations length: 10\n",
            " --- GetMetrics --- [1]@10 (backbone_model=ease)\n",
            "Metrics@5: C-Equity: 0.0410 (±0.0425), U-Parity: 0.07364545558772512 (±0.05442334470000494)\n",
            "[GetUserHistory] user_id: 2\n",
            "[FilterCandidateSet] User[2], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[2] history length: 258\n",
            "[CheckRecommendations] User[2] - Recommendations length: 10\n",
            " --- GetMetrics --- [2]@10 (backbone_model=ease)\n",
            "Metrics@6: C-Equity: 0.0410 (±0.0426), U-Parity: 0.07364545558772512 (±0.05442334470000494)\n",
            "[GetUserHistory] user_id: 3[FilterCandidateSet] User[3], Model: ease, Top K: 20\n",
            "\n",
            "[GetUserPreferences] User[3] history length: 2147\n",
            "[CheckRecommendations] User[3] - Recommendations length: 10\n",
            " --- GetMetrics --- [3]@10 (backbone_model=ease)\n",
            "Metrics@7: C-Equity: 0.0410 (±0.0425), U-Parity: 0.07346169961565603 (±0.0544507976844551)\n",
            "[GetUserHistory] user_id: 4\n",
            "[FilterCandidateSet] User[4], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[4] history length: 2147\n",
            "[CheckRecommendations] User[4] - Recommendations length: 10\n",
            " --- GetMetrics --- [4]@10 (backbone_model=ease)\n",
            "Metrics@8: C-Equity: 0.0409 (±0.0425), U-Parity: 0.07315543966220754 (±0.05467475388115781)\n",
            "[FilterCandidateSet] User[5], Model: ease, Top K: 20[GetUserHistory] user_id: 5\n",
            "\n",
            "[GetUserPreferences] User[5] history length: 1904\n",
            "[CheckRecommendations] User[5] - Recommendations length: 10\n",
            "[CheckRecommendations] User[5] - Recommendations length: 10\n",
            "[CheckRecommendations] User[5] - Recommendations length: 10\n",
            "[CheckRecommendations] User[5] - Recommendations length: 10\n",
            "[CheckRecommendations] User[5] - Recommendations length: 10\n",
            "[CheckRecommendations] User[5] - Recommendations length: 10\n",
            " --- GetMetrics --- [5]@10 (backbone_model=ease)\n",
            "Metrics@9: C-Equity: 0.0410 (±0.0426), U-Parity: 0.07327794364358692 (±0.05452760293123477)\n",
            "[GetUserHistory] user_id: 6\n",
            "[FilterCandidateSet] User[6], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[6] history length: 221\n",
            "[CheckRecommendations] User[6] - Recommendations length: 10\n",
            " --- GetMetrics --- [6]@10 (backbone_model=ease)\n",
            "Metrics@10: C-Equity: 0.0410 (±0.0426), U-Parity: 0.07327794364358692 (±0.05452760293123477)\n",
            "[GetUserHistory] user_id: 7\n",
            "[FilterCandidateSet] User[7], Model: ease, Top K: 20\n",
            "[GetUserPreferences] User[7] history length: 891\n",
            "[CheckRecommendations] User[7] - Recommendations length: 10\n",
            "[CheckRecommendations] User[7] - Recommendations length: 10\n",
            " --- GetMetrics --- [7]@10 (backbone_model=ease)\n",
            "Metrics@11: C-Equity: 0.0410 (±0.0425), U-Parity: 0.07332741430748324 (±0.054545336635514044)\n",
            "[GetUserHistory] user_id: 8[FilterCandidateSet] User[8], Model: ease, Top K: 20\n",
            "\n",
            "[GetUserPreferences] User[8] history length: 1855\n",
            "[CheckRecommendations] User[8] - Recommendations length: 10\n",
            " --- GetMetrics --- [8]@10 (backbone_model=ease)\n",
            "Metrics@12: C-Equity: 0.0410 (±0.0425), U-Parity: 0.07345109096722402 (±0.05456089929280248)\n",
            "[FilterCandidateSet] User[9], Model: ease, Top K: 20\n",
            "[GetUserHistory] user_id: 9\n",
            "[GetUserPreferences] User[9] history length: 626\n",
            "[CheckRecommendations] User[9] - Recommendations length: 10\n",
            " --- GetMetrics --- [9]@10 (backbone_model=ease)\n",
            "Metrics@13: C-Equity: 0.0410 (±0.0426), U-Parity: 0.07375735092067252 (±0.05466802176227711)\n"
          ]
        }
      ],
      "source": [
        "RETRY_ALLOWED = 3\n",
        "\n",
        "for user_id in range(0,10):\n",
        "    \n",
        "    n_try = 1\n",
        "    while n_try < RETRY_ALLOWED:\n",
        "        try:\n",
        "            config = {\"configurable\":{\"thread_id\": f\"thread_{experiment_id}\",\"user_id\": user_id}}\n",
        "\n",
        "            result = agent.invoke(\n",
        "                {\n",
        "                    \"messages\": [{\"role\": \"user\", \"content\": f\"Recommend movies for the user {user_id}\"}],\n",
        "                },\n",
        "                config=config,\n",
        "                context=UserContext(user_id=user_id,session_id=experiment_id)\n",
        "            )\n",
        "            break # If successfull, continue to the next user.\n",
        "            #print(result['messages'][-1].pretty_print())\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"[Users loop] - Problem generating recommendation for the User[{user_id}]: {e}\")\n",
        "            n_try += 1\n",
        "            if n_try >= RETRY_ALLOWED:\n",
        "                logger.error(f\"[Users loop] - Error: it was not possible generate recommendation for the user[{user_id}]: {e}\")\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d1041ae",
      "metadata": {},
      "source": [
        "# Calculate final result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "id": "6424bd05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "u-parity@1 0.07354651425993247\n",
            "u-parity@2 0.07354651425993249\n",
            "u-parity@3 0.07364545558772512\n",
            "u-parity@4 0.07364545558772512\n",
            "u-parity@5 0.07364545558772512\n",
            "u-parity@6 0.07364545558772512\n",
            "u-parity@7 0.07346169961565603\n",
            "u-parity@8 0.07315543966220754\n",
            "u-parity@9 0.07327794364358692\n",
            "u-parity@10 0.07327794364358692\n",
            "c-equity@1 0.04095798440697764\n",
            "c-equity@2 0.04095798440697764\n",
            "c-equity@3 0.04097282560614654\n",
            "c-equity@4 0.04097282560614654\n",
            "c-equity@5 0.04097282560614654\n",
            "c-equity@6 0.040997326402422415\n",
            "c-equity@7 0.04096670040707756\n",
            "c-equity@8 0.0408993232173189\n",
            "c-equity@9 0.040960575208008596\n",
            "c-equity@10 0.040963048741203406\n"
          ]
        }
      ],
      "source": [
        "# u-parity\n",
        "namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "metric_items = store.search(namespace_for_uparity)\n",
        "uparity_list = []\n",
        "for metric in metric_items:\n",
        "    print(f\"u-parity@{metric.key}\" , metric.value['mean'])\n",
        "    uparity_list.append(metric.value)\n",
        "\n",
        "# c-equity\n",
        "namespace_for_cequity = (\"metrics\",\"c-equity\")\n",
        "metric_items = store.search(namespace_for_cequity)\n",
        "cequity_list = []\n",
        "for metric in metric_items:\n",
        "    print(f\"c-equity@{metric.key}\" , metric.value['mean'])\n",
        "    cequity_list.append(metric.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "id": "52f17f21",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result = pd.DataFrame(uparity_list,columns=['mean','std']).rename(columns={\"mean\":\"u-parity\", \"std\":'u-parity_std'}).join(pd.DataFrame(cequity_list,columns=['mean','std']).rename(columns={\"mean\":\"c-equity\", \"std\":'c-equity_std'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "id": "5062b79b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Fairness metrics in Reranking'}, xlabel='Iteration', ylabel='Score'>"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_result[['u-parity','c-equity']].plot(xlabel='Iteration', ylabel='Score', title='Fairness metrics in Reranking')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc7ee50",
      "metadata": {},
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "4fcfb8a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FilterCandidateSet] User[123], Model: ease, Top K: 20[GetUserHistory] user_id: 123\n",
            "\n",
            "[GetUserPreferences] User[123] history length: 845\n",
            "[CheckRecommendations] User[123] - Recommendations length: 10\n",
            "[CheckRecommendations] User[123] - Recommendations length: 10\n",
            "[CheckRecommendations] User[123] - Recommendations length: 10\n",
            " --- GetMetrics --- [123]@10 (backbone_model=ease)\n",
            "Metrics@2: C-Equity: 0.0410 (±0.0425), U-Parity: 0.07354651425993249 (±0.05442441471627253)\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: RecommendationResponse\n",
            "\n",
            "Returning structured response: user_id=123 recommendations=['The Green Mile', 'The Silence of the Lambs', 'GoodFellas', 'The Shawshank Redemption', 'Pulp Fiction', 'The Usual Suspects', 'Fight Club', 'Requiem for a Dream', 'L.A. Confidential', 'Donnie Brasco']\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "user_id = 123\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": f\"Recommend movies for the user {user_id}\"}],\n",
        "    },\n",
        "    config=config,\n",
        "    context=UserContext(user_id=user_id,session_id=experiment_id),\n",
        "    \n",
        ")\n",
        "\n",
        "print(result['messages'][-1].pretty_print())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8149e561",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Item(namespace=['123', 'recommendations'], key='1', value={'recommended_items': ['Green Mile, The (1999)', 'Silence of the Lambs, The (1991)', 'GoodFellas (1990)', 'Shawshank Redemption, The (1994)', 'Pulp Fiction (1994)', 'Usual Suspects, The (1995)', 'Fight Club (1999)', 'Requiem for a Dream (2000)', 'L.A. Confidential (1997)', 'Donnie Brasco (1997)']}, created_at='2025-11-24T01:30:56.539461+00:00', updated_at='2025-11-24T01:30:56.539462+00:00')"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_memory = (str(user_id),\"recommendations\")\n",
        "store.get(namespace_for_memory,experiment_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "id": "178654a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['9', 'preferences'], key='1', value={'infered_preferences': 'Based on your watched movies, you seem to prioritize the following features in your movie preferences:\\n\\n1. **Genre Diversity with a Focus on Action, Adventure, and Sci-Fi:** You enjoy high-energy films like *Die Hard*, *The Terminator*, and *Star Wars*, indicating a taste for action-packed and adventurous stories. Sci-fi classics like *The Matrix*, *Twelve Monkeys*, and *Contact* also appeal to you, suggesting an interest in futuristic and speculative themes.\\n\\n2. **Mix of Humor and Light-hearted Elements:** Films such as *Ghostbusters*, *Sister Act 2*, *The Love Bug*, and *Shall We Dance?* suggest you enjoy movies that combine comedy, music, and uplifting vibes.\\n\\n3. **Drama and Thought-Provoking Content:** You seem to appreciate films that explore human stories and deeper themes, like *Good Will Hunting*, *Dead Poets Society*, and *The Sixth Sense*, indicating an interest in emotionally engaging and psychologically compelling narratives.\\n\\n4. **Classic and Iconic Films:** Your choices include timeless classics such as *The Wizard of Oz*, *Back to the Future*, and *E.T.*, showing an appreciation for enduring and culturally significant movies.\\n\\n5. **Family and Child-Friendly Content:** Movies like *Stuart Little*, *The Pagemaster*, and *The Lion King* suggest you enjoy family-oriented films with heartwarming stories and fantasy elements.\\n\\n**In summary:** You prefer a diverse mix of action, adventure, sci-fi, comedy, and heartfelt drama, with an affinity for both classic and uplifting family movies. This blend points to a well-rounded taste that values exciting storytelling balanced with emotional depth and humor.'}, created_at='2025-11-24T01:42:50.775889+00:00', updated_at='2025-11-24T01:42:50.775891+00:00', score=None),\n",
              " Item(namespace=['9', 'recommendations'], key='1', value={'recommended_items': ['Abyss, The (1989)', 'Indiana Jones and the Last Crusade (1989)', 'Star Wars: Episode V - The Empire Strikes Back (1980)', 'Jurassic Park (1993)', 'Men in Black (1997)', 'Star Trek: The Wrath of Khan (1982)', 'Braveheart (1995)', 'Toy Story (1995)', 'Total Recall (1990)', 'Hunt for Red October, The (1990)']}, created_at='2025-11-24T01:42:51.875507+00:00', updated_at='2025-11-24T01:42:51.875509+00:00', score=None)]"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_memory = (str(user_id),)\n",
        "store.search(namespace_for_memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "id": "db5189b4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['metrics', 'c-equity'], key='1', value={'mean': 0.04095798440697764, 'std': 0.04251155367150264}, created_at='2025-11-24T01:30:32.042576+00:00', updated_at='2025-11-24T01:30:32.042576+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='2', value={'mean': 0.04095798440697764, 'std': 0.04252643810267245}, created_at='2025-11-24T01:30:59.191854+00:00', updated_at='2025-11-24T01:30:59.191855+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='3', value={'mean': 0.04097282560614654, 'std': 0.04254220934442971}, created_at='2025-11-24T01:36:20.796131+00:00', updated_at='2025-11-24T01:36:20.796132+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='4', value={'mean': 0.04097282560614654, 'std': 0.04254220934442971}, created_at='2025-11-24T01:41:22.242592+00:00', updated_at='2025-11-24T01:41:22.242593+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='5', value={'mean': 0.04097282560614654, 'std': 0.04254220934442971}, created_at='2025-11-24T01:41:28.460471+00:00', updated_at='2025-11-24T01:41:28.460471+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='6', value={'mean': 0.040997326402422415, 'std': 0.04256764104289328}, created_at='2025-11-24T01:41:36.680641+00:00', updated_at='2025-11-24T01:41:36.680642+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='7', value={'mean': 0.04096670040707756, 'std': 0.042549738205585816}, created_at='2025-11-24T01:41:47.002114+00:00', updated_at='2025-11-24T01:41:47.002114+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='8', value={'mean': 0.0408993232173189, 'std': 0.042502892213009826}, created_at='2025-11-24T01:41:58.522076+00:00', updated_at='2025-11-24T01:41:58.522081+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='9', value={'mean': 0.040960575208008596, 'std': 0.042555019532350524}, created_at='2025-11-24T01:42:13.756461+00:00', updated_at='2025-11-24T01:42:13.756462+00:00', score=None),\n",
              " Item(namespace=['metrics', 'c-equity'], key='10', value={'mean': 0.040963048741203406, 'std': 0.042552675589526606}, created_at='2025-11-24T01:42:23.346494+00:00', updated_at='2025-11-24T01:42:23.346495+00:00', score=None)]"
            ]
          },
          "execution_count": 277,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_memory = (\"metrics\",\"c-equity\")\n",
        "store.search(namespace_for_memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "id": "64e15311",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Item(namespace=['metrics', 'u-parity'], key='1', value={'mean': 0.07354651425993247, 'std': 0.0542062592059169}, created_at='2025-11-24T01:30:32.042580+00:00', updated_at='2025-11-24T01:30:32.042580+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='2', value={'mean': 0.07354651425993249, 'std': 0.05442441471627253}, created_at='2025-11-24T01:30:59.191859+00:00', updated_at='2025-11-24T01:30:59.191859+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='3', value={'mean': 0.07364545558772512, 'std': 0.05442334470000494}, created_at='2025-11-24T01:36:20.796136+00:00', updated_at='2025-11-24T01:36:20.796136+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='4', value={'mean': 0.07364545558772512, 'std': 0.05442334470000494}, created_at='2025-11-24T01:41:22.242596+00:00', updated_at='2025-11-24T01:41:22.242597+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='5', value={'mean': 0.07364545558772512, 'std': 0.05442334470000494}, created_at='2025-11-24T01:41:28.460475+00:00', updated_at='2025-11-24T01:41:28.460475+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='6', value={'mean': 0.07364545558772512, 'std': 0.05442334470000494}, created_at='2025-11-24T01:41:36.680650+00:00', updated_at='2025-11-24T01:41:36.680651+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='7', value={'mean': 0.07346169961565603, 'std': 0.0544507976844551}, created_at='2025-11-24T01:41:47.002118+00:00', updated_at='2025-11-24T01:41:47.002118+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='8', value={'mean': 0.07315543966220754, 'std': 0.05467475388115781}, created_at='2025-11-24T01:41:58.522108+00:00', updated_at='2025-11-24T01:41:58.522109+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='9', value={'mean': 0.07327794364358692, 'std': 0.05452760293123477}, created_at='2025-11-24T01:42:13.756471+00:00', updated_at='2025-11-24T01:42:13.756472+00:00', score=None),\n",
              " Item(namespace=['metrics', 'u-parity'], key='10', value={'mean': 0.07327794364358692, 'std': 0.05452760293123477}, created_at='2025-11-24T01:42:23.346507+00:00', updated_at='2025-11-24T01:42:23.346508+00:00', score=None)]"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "namespace_for_uparity = (\"metrics\",\"u-parity\")\n",
        "store.search(namespace_for_uparity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d5bc5b5e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x130962e50>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2819aac",
      "metadata": {},
      "source": [
        "# Print all messages in the result\n",
        "for message in result['messages']:\n",
        "    print(message.pretty_print())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "095ccbf1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RecommendationResponse(user_id=123, recommendations=['Back to the Future', \"Pee-wee's Big Adventure\", 'Forrest Gump', 'The Shawshank Redemption', 'The Silence of the Lambs', 'The Usual Suspects', 'The Sixth Sense', 'Apollo 13', \"Jacob's Ladder\", 'GoodFellas'])"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['structured_response']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "1cee4055",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on your watchlist, your key preferences seem to include:\\n\\n1. **Diverse Genres with a Focus on Drama and Thriller:** You enjoy intense narratives, from psychological thrillers (The Silence of the Lambs, The Sixth Sense) to crime and noir (Fargo, Reservoir Dogs, L.A. Confidential).\\n\\n2. **Strong Character Development and Emotional Depth:** Films like Forrest Gump, Schindler’s List, The Green Mile, and Saving Private Ryan showcase a preference for emotionally compelling stories with memorable characters.\\n\\n3. **Clever, Thought-Provoking, and Stylish Films:** You appreciate movies with unique storytelling, like Being John Malkovich, Pulp Fiction, Run Lola Run, and The Matrix.\\n\\n4. **Humor and Quirky Elements:** You include comedies and offbeat films such as Pee-wee’s Big Adventure, Grosse Pointe Blank, Friday, and Clerks, indicating an appreciation for humor and eccentricity.\\n\\n5. **Awards and Critical Acclaim:** Many of your picks are critically acclaimed or award-winning, reflecting a taste for well-crafted, impactful cinema.\\n\\n6. **Variety of Settings and Time Periods:** Your choices span historical (Schindler’s List, Braveheart) and imaginative worlds (Aladdin, The Lion King, Toy Story).\\n\\n**In summary:** You prefer films that combine emotional depth, clever storytelling, strong characters, and stylistic flair across various genres—especially dramas, thrillers, and critically acclaimed films with unique narratives.'"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['preferences']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1413e7c8",
      "metadata": {},
      "source": [
        "# Discussed on last meeting\n",
        "\n",
        "Goal: given a set of users, produce a set of k fair recommendations for each user.\n",
        "\n",
        "Variant: individual fairness\n",
        "\n",
        "Variant 1: no fairness + individual\n",
        "\n",
        "variant2: memory+holistic fairness\n",
        "\n",
        "-----\n",
        "\n",
        "Variant2: holistic and no memory\n",
        "\n",
        "Verify if an LLM is able to enforce fairness\n",
        "\n",
        "Verify an LLM is able to enforce fairness holistically or individually\n",
        "\n",
        "Impact of memory on the LLM’s ability to enforce fairness\n",
        "\n",
        "\n",
        "-> Implementar o componente de memória\n",
        "-> Pensar em como estruturar os prompts para cada variante com base na memória\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "73528439",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RecommendationResponse(user_id=123, recommendations=['Back to the Future', \"Pee-wee's Big Adventure\", 'Forrest Gump', 'The Shawshank Redemption', 'The Silence of the Lambs', 'The Usual Suspects', 'The Sixth Sense', 'Apollo 13', \"Jacob's Ladder\", 'GoodFellas'])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resp : RecommendationResponse = result['structured_response']\n",
        "resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "de73a701",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_id</th>\n",
              "      <th>Item_id</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Gender</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [User_id, Item_id, Rating, Timestamp, Gender, datetime]\n",
              "Index: []"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_target_user_id = get_raw_user_ids(ratings_pp, [resp.user_id])[0]\n",
        "test_ratings[test_ratings.User_id == raw_target_user_id]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.11.13)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
